

================================================================
== Vitis HLS Report for 'neural_network'
================================================================
* Date:           Sun Sep 15 02:59:38 2024

* Version:        2023.1 (Build 3854077 on May  4 2023)
* Project:        hlsc_fcnn_iris
* Solution:       solution1 (Vivado IP Flow Target)
* Product family: artix7
* Target device:  xc7a35t-cpg236-1


================================================================
== Performance Estimates
================================================================
+ Timing: 
    * Summary: 
    +--------+----------+----------+------------+
    |  Clock |  Target  | Estimated| Uncertainty|
    +--------+----------+----------+------------+
    |ap_clk  |  10.00 ns|  6.893 ns|     2.70 ns|
    +--------+----------+----------+------------+

+ Latency: 
    * Summary: 
    +---------+---------+----------+----------+-----+-----+---------+
    |  Latency (cycles) |  Latency (absolute) |  Interval | Pipeline|
    |   min   |   max   |    min   |    max   | min | max |   Type  |
    +---------+---------+----------+----------+-----+-----+---------+
    |      313|      313|  3.130 us|  3.130 us|  314|  314|       no|
    +---------+---------+----------+----------+-----+-----+---------+

    + Detail: 
        * Instance: 
        +--------------------------------------------------------------------+---------------------------------------------------------+---------+---------+-----------+-----------+-----+-----+---------+
        |                                                                    |                                                         |  Latency (cycles) |   Latency (absolute)  |  Interval | Pipeline|
        |                              Instance                              |                          Module                         |   min   |   max   |    min    |    max    | min | max |   Type  |
        +--------------------------------------------------------------------+---------------------------------------------------------+---------+---------+-----------+-----------+-----+-----+---------+
        |grp_neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3_fu_202  |neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3  |       34|       34|   0.340 us|   0.340 us|   34|   34|       no|
        |grp_neural_network_Pipeline_VITIS_LOOP_70_4_fu_213                  |neural_network_Pipeline_VITIS_LOOP_70_4                  |       15|       15|   0.150 us|   0.150 us|   15|   15|       no|
        |grp_neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8_fu_232  |neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8  |       26|       26|   0.260 us|   0.260 us|   26|   26|       no|
        |grp_neural_network_Pipeline_VITIS_LOOP_21_1_fu_243                  |neural_network_Pipeline_VITIS_LOOP_21_1                  |        4|        4|  40.000 ns|  40.000 ns|    4|    4|       no|
        |grp_neural_network_Pipeline_VITIS_LOOP_92_9_fu_251                  |neural_network_Pipeline_VITIS_LOOP_92_9                  |       17|       17|   0.170 us|   0.170 us|   17|   17|       no|
        |grp_neural_network_Pipeline_VITIS_LOOP_26_2_fu_270                  |neural_network_Pipeline_VITIS_LOOP_26_2                  |       10|       10|   0.100 us|   0.100 us|   10|   10|       no|
        |grp_neural_network_Pipeline_VITIS_LOOP_32_3_fu_291                  |neural_network_Pipeline_VITIS_LOOP_32_3                  |       92|       92|   0.920 us|   0.920 us|   92|   92|       no|
        +--------------------------------------------------------------------+---------------------------------------------------------+---------+---------+-----------+-----------+-----+-----+---------+

        * Loop: 
        +-------------------+---------+---------+----------+-----------+-----------+------+----------+
        |                   |  Latency (cycles) | Iteration|  Initiation Interval  | Trip |          |
        |     Loop Name     |   min   |   max   |  Latency |  achieved |   target  | Count| Pipelined|
        +-------------------+---------+---------+----------+-----------+-----------+------+----------+
        |- VITIS_LOOP_60_1  |      106|      106|        53|          -|          -|     2|        no|
        |- VITIS_LOOP_82_6  |       94|       94|        47|          -|          -|     2|        no|
        +-------------------+---------+---------+----------+-----------+-----------+------+----------+

============================================================
+ Verbose Summary: Synthesis Manager
============================================================
InlineROM: 1
ExposeGlobal: 0
============================================================
+ Verbose Summary: CDFG Model
============================================================
IsTopModel: 1
ResetActiveHigh: 1
IsCombinational: 0
IsDatapathOnly: 0
HasWiredReturn: 1
HasMFsm: 0
HasVarLatency: 1
IsPipeline: 0
IsRtlPipelined: 0
IsInstanceOverlapped: 0
IsDontTouch: 0
HasImplIP: 0
IsGatedGlobalClock: 0


============================================================
+ Verbose Summary: Schedule
============================================================
* Number of FSM states : 14
* Pipeline : 0
* Dataflow Pipeline: 0

* FSM state transitions: 
1 --> 2 
2 --> 3 6 
3 --> 4 
4 --> 5 
5 --> 2 
6 --> 7 10 
7 --> 8 
8 --> 9 
9 --> 6 
10 --> 11 
11 --> 12 
12 --> 13 
13 --> 14 
14 --> 

* FSM state operations: 

State 1 <SV = 0> <Delay = 2.15>
ST_1 : Operation 15 [1/1] (0.00ns)   --->   "%tile = alloca i32 1"   --->   Operation 15 'alloca' 'tile' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 16 [1/1] (0.00ns)   --->   "%sum_2_loc = alloca i64 1"   --->   Operation 16 'alloca' 'sum_2_loc' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 17 [1/1] (0.00ns)   --->   "%max_val_loc = alloca i64 1"   --->   Operation 17 'alloca' 'max_val_loc' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 18 [1/1] (0.00ns)   --->   "%spectopmodule_ln38 = spectopmodule void @_ssdm_op_SpecTopModule, void @empty_6" [nn.cpp:38]   --->   Operation 18 'spectopmodule' 'spectopmodule_ln38' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 19 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %input_0"   --->   Operation 19 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 20 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_0, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_19, void @empty_12, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 20 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 21 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_0, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 21 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 22 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %input_1"   --->   Operation 22 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 23 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_1, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_19, void @empty_10, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 23 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 24 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_1, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 24 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 25 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %input_2"   --->   Operation 25 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 26 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_2, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_19, void @empty_2, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 26 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 27 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_2, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 27 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 28 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %input_3"   --->   Operation 28 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 29 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_3, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_19, void @empty_9, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 29 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 30 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %input_3, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 30 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 31 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %output_0"   --->   Operation 31 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 32 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %output_0, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_3, void @empty_12, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 32 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 33 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %output_0, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 33 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 34 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %output_1"   --->   Operation 34 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 35 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %output_1, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_3, void @empty_2, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 35 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 36 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %output_1, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 36 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 37 [1/1] (0.00ns)   --->   "%specbitsmap_ln0 = specbitsmap void @_ssdm_op_SpecBitsMap, i16 %output_2"   --->   Operation 37 'specbitsmap' 'specbitsmap_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 38 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %output_2, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_3, void @empty_8, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 38 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 39 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i16 %output_2, void @empty_11, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_13, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 39 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 40 [1/1] (0.00ns)   --->   "%specinterface_ln0 = specinterface void @_ssdm_op_SpecInterface, i32 0, void @empty_14, i32 0, i32 0, void @empty_13, i32 0, i32 0, void @empty_1, void @empty_13, void @empty_13, i32 0, i32 0, i32 0, i32 0, void @empty_13, void @empty_13, i32 4294967295, i32 0"   --->   Operation 40 'specinterface' 'specinterface_ln0' <Predicate = true> <Delay = 0.00>
ST_1 : Operation 41 [1/1] (2.15ns)   --->   "%layer1_output = alloca i64 1" [nn.cpp:44]   --->   Operation 41 'alloca' 'layer1_output' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 42 [1/1] (2.15ns)   --->   "%layer1_output_1 = alloca i64 1" [nn.cpp:44]   --->   Operation 42 'alloca' 'layer1_output_1' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 43 [1/1] (2.15ns)   --->   "%layer1_output_2 = alloca i64 1" [nn.cpp:44]   --->   Operation 43 'alloca' 'layer1_output_2' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 44 [1/1] (2.15ns)   --->   "%layer1_output_3 = alloca i64 1" [nn.cpp:44]   --->   Operation 44 'alloca' 'layer1_output_3' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 45 [1/1] (2.15ns)   --->   "%layer1_weight_tile = alloca i64 1" [nn.cpp:53]   --->   Operation 45 'alloca' 'layer1_weight_tile' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 46 [1/1] (2.15ns)   --->   "%layer1_weight_tile_1 = alloca i64 1" [nn.cpp:53]   --->   Operation 46 'alloca' 'layer1_weight_tile_1' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 47 [1/1] (2.15ns)   --->   "%layer1_weight_tile_2 = alloca i64 1" [nn.cpp:53]   --->   Operation 47 'alloca' 'layer1_weight_tile_2' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 48 [1/1] (2.15ns)   --->   "%layer1_weight_tile_3 = alloca i64 1" [nn.cpp:53]   --->   Operation 48 'alloca' 'layer1_weight_tile_3' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 49 [1/1] (2.15ns)   --->   "%layer2_weight_tile = alloca i64 1" [nn.cpp:54]   --->   Operation 49 'alloca' 'layer2_weight_tile' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 50 [1/1] (2.15ns)   --->   "%layer2_weight_tile_1 = alloca i64 1" [nn.cpp:54]   --->   Operation 50 'alloca' 'layer2_weight_tile_1' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 51 [1/1] (2.15ns)   --->   "%layer2_weight_tile_2 = alloca i64 1" [nn.cpp:54]   --->   Operation 51 'alloca' 'layer2_weight_tile_2' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 52 [1/1] (2.15ns)   --->   "%layer2_weight_tile_3 = alloca i64 1" [nn.cpp:54]   --->   Operation 52 'alloca' 'layer2_weight_tile_3' <Predicate = true> <Delay = 2.15>
ST_1 : Operation 53 [1/1] (1.00ns)   --->   "%input_0_read = read i16 @_ssdm_op_Read.s_axilite.i16P0A, i16 %input_0"   --->   Operation 53 'read' 'input_0_read' <Predicate = true> <Delay = 1.00> <CoreInst = "s_axilite">   --->   Core 114 's_axilite' <Latency = 0> <II = 1> <Delay = 1.00> <Adapter> <Opcode : 'read' 'write'>
ST_1 : Operation 54 [1/1] (1.00ns)   --->   "%input_1_read = read i16 @_ssdm_op_Read.s_axilite.i16P0A, i16 %input_1"   --->   Operation 54 'read' 'input_1_read' <Predicate = true> <Delay = 1.00> <CoreInst = "s_axilite">   --->   Core 114 's_axilite' <Latency = 0> <II = 1> <Delay = 1.00> <Adapter> <Opcode : 'read' 'write'>
ST_1 : Operation 55 [1/1] (1.00ns)   --->   "%input_2_read = read i16 @_ssdm_op_Read.s_axilite.i16P0A, i16 %input_2"   --->   Operation 55 'read' 'input_2_read' <Predicate = true> <Delay = 1.00> <CoreInst = "s_axilite">   --->   Core 114 's_axilite' <Latency = 0> <II = 1> <Delay = 1.00> <Adapter> <Opcode : 'read' 'write'>
ST_1 : Operation 56 [1/1] (1.00ns)   --->   "%input_3_read = read i16 @_ssdm_op_Read.s_axilite.i16P0A, i16 %input_3"   --->   Operation 56 'read' 'input_3_read' <Predicate = true> <Delay = 1.00> <CoreInst = "s_axilite">   --->   Core 114 's_axilite' <Latency = 0> <II = 1> <Delay = 1.00> <Adapter> <Opcode : 'read' 'write'>
ST_1 : Operation 57 [1/1] (1.61ns)   --->   "%store_ln60 = store i4 0, i4 %tile" [nn.cpp:60]   --->   Operation 57 'store' 'store_ln60' <Predicate = true> <Delay = 1.61>
ST_1 : Operation 58 [1/1] (0.00ns)   --->   "%br_ln60 = br void %VITIS_LOOP_62_2" [nn.cpp:60]   --->   Operation 58 'br' 'br_ln60' <Predicate = true> <Delay = 0.00>

State 2 <SV = 1> <Delay = 3.38>
ST_2 : Operation 59 [1/1] (0.00ns)   --->   "%tile_2 = load i4 %tile" [nn.cpp:60]   --->   Operation 59 'load' 'tile_2' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 60 [1/1] (0.00ns)   --->   "%tmp = bitselect i1 @_ssdm_op_BitSelect.i1.i4.i32, i4 %tile_2, i32 3" [nn.cpp:60]   --->   Operation 60 'bitselect' 'tmp' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 61 [1/1] (0.00ns)   --->   "%br_ln60 = br i1 %tmp, void %VITIS_LOOP_62_2.split, void %VITIS_LOOP_84_7.preheader" [nn.cpp:60]   --->   Operation 61 'br' 'br_ln60' <Predicate = true> <Delay = 0.00>
ST_2 : Operation 62 [1/1] (0.00ns)   --->   "%trunc_ln60 = trunc i4 %tile_2" [nn.cpp:60]   --->   Operation 62 'trunc' 'trunc_ln60' <Predicate = (!tmp)> <Delay = 0.00>
ST_2 : Operation 63 [2/2] (0.00ns)   --->   "%call_ln60 = call void @neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3, i9 %layer1_weight_tile, i3 %trunc_ln60, i9 %layer1_weight_tile_3, i9 %layer1_weight_tile_2, i9 %layer1_weight_tile_1, i9 %layer1_weights" [nn.cpp:60]   --->   Operation 63 'call' 'call_ln60' <Predicate = (!tmp)> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_2 : Operation 64 [1/1] (1.77ns)   --->   "%add_ln60 = add i4 %tile_2, i4 4" [nn.cpp:60]   --->   Operation 64 'add' 'add_ln60' <Predicate = (!tmp)> <Delay = 1.77> <CoreInst = "Adder">   --->   Core 1 'Adder' <Latency = 0> <II = 1> <Delay = 1.77> <FuncUnit> <Opcode : 'add' 'sub'> <InPorts = 2> <OutPorts = 1>
ST_2 : Operation 65 [1/1] (1.61ns)   --->   "%store_ln60 = store i4 %add_ln60, i4 %tile" [nn.cpp:60]   --->   Operation 65 'store' 'store_ln60' <Predicate = (!tmp)> <Delay = 1.61>
ST_2 : Operation 66 [1/1] (0.00ns)   --->   "%tile_1 = alloca i32 1"   --->   Operation 66 'alloca' 'tile_1' <Predicate = (tmp)> <Delay = 0.00>
ST_2 : Operation 67 [1/1] (0.00ns)   --->   "%p_0_0_0114_i1 = alloca i32 1"   --->   Operation 67 'alloca' 'p_0_0_0114_i1' <Predicate = (tmp)> <Delay = 0.00>
ST_2 : Operation 68 [1/1] (0.00ns)   --->   "%conv_i_i_le8_lcssa15 = alloca i32 1"   --->   Operation 68 'alloca' 'conv_i_i_le8_lcssa15' <Predicate = (tmp)> <Delay = 0.00>
ST_2 : Operation 69 [1/1] (0.00ns)   --->   "%conv_i_i_le10_lcssa17 = alloca i32 1"   --->   Operation 69 'alloca' 'conv_i_i_le10_lcssa17' <Predicate = (tmp)> <Delay = 0.00>
ST_2 : Operation 70 [1/1] (0.00ns)   --->   "%conv_i_i_le12_lcssa19 = alloca i32 1"   --->   Operation 70 'alloca' 'conv_i_i_le12_lcssa19' <Predicate = (tmp)> <Delay = 0.00>
ST_2 : Operation 71 [1/1] (1.61ns)   --->   "%store_ln82 = store i4 0, i4 %tile_1" [nn.cpp:82]   --->   Operation 71 'store' 'store_ln82' <Predicate = (tmp)> <Delay = 1.61>
ST_2 : Operation 72 [1/1] (0.00ns)   --->   "%br_ln82 = br void %VITIS_LOOP_84_7" [nn.cpp:82]   --->   Operation 72 'br' 'br_ln82' <Predicate = (tmp)> <Delay = 0.00>

State 3 <SV = 2> <Delay = 0.00>
ST_3 : Operation 73 [1/2] (0.00ns)   --->   "%call_ln60 = call void @neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3, i9 %layer1_weight_tile, i3 %trunc_ln60, i9 %layer1_weight_tile_3, i9 %layer1_weight_tile_2, i9 %layer1_weight_tile_1, i9 %layer1_weights" [nn.cpp:60]   --->   Operation 73 'call' 'call_ln60' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 4 <SV = 3> <Delay = 0.00>
ST_4 : Operation 74 [2/2] (0.00ns)   --->   "%call_ln60 = call void @neural_network_Pipeline_VITIS_LOOP_70_4, i15 %layer1_output_3, i15 %layer1_output_2, i15 %layer1_output_1, i15 %layer1_output, i3 %trunc_ln60, i9 %layer1_weight_tile, i16 %input_0_read, i9 %layer1_weight_tile_1, i16 %input_1_read, i9 %layer1_weight_tile_2, i16 %input_2_read, i9 %layer1_weight_tile_3, i16 %input_3_read, i7 %layer1_bias" [nn.cpp:60]   --->   Operation 74 'call' 'call_ln60' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 5 <SV = 4> <Delay = 0.00>
ST_5 : Operation 75 [1/1] (0.00ns)   --->   "%speclooptripcount_ln60 = speclooptripcount void @_ssdm_op_SpecLoopTripCount, i64 2, i64 2, i64 2" [nn.cpp:60]   --->   Operation 75 'speclooptripcount' 'speclooptripcount_ln60' <Predicate = true> <Delay = 0.00>
ST_5 : Operation 76 [1/1] (0.00ns)   --->   "%specloopname_ln60 = specloopname void @_ssdm_op_SpecLoopName, void @empty_15" [nn.cpp:60]   --->   Operation 76 'specloopname' 'specloopname_ln60' <Predicate = true> <Delay = 0.00>
ST_5 : Operation 77 [1/2] (0.00ns)   --->   "%call_ln60 = call void @neural_network_Pipeline_VITIS_LOOP_70_4, i15 %layer1_output_3, i15 %layer1_output_2, i15 %layer1_output_1, i15 %layer1_output, i3 %trunc_ln60, i9 %layer1_weight_tile, i16 %input_0_read, i9 %layer1_weight_tile_1, i16 %input_1_read, i9 %layer1_weight_tile_2, i16 %input_2_read, i9 %layer1_weight_tile_3, i16 %input_3_read, i7 %layer1_bias" [nn.cpp:60]   --->   Operation 77 'call' 'call_ln60' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_5 : Operation 78 [1/1] (0.00ns)   --->   "%br_ln60 = br void %VITIS_LOOP_62_2" [nn.cpp:60]   --->   Operation 78 'br' 'br_ln60' <Predicate = true> <Delay = 0.00>

State 6 <SV = 2> <Delay = 6.69>
ST_6 : Operation 79 [1/1] (0.00ns)   --->   "%tile_3 = load i4 %tile_1" [nn.cpp:82]   --->   Operation 79 'load' 'tile_3' <Predicate = true> <Delay = 0.00>
ST_6 : Operation 80 [1/1] (0.00ns)   --->   "%trunc_ln82 = trunc i4 %tile_3" [nn.cpp:82]   --->   Operation 80 'trunc' 'trunc_ln82' <Predicate = true> <Delay = 0.00>
ST_6 : Operation 81 [1/1] (0.00ns)   --->   "%tmp_10 = bitselect i1 @_ssdm_op_BitSelect.i1.i4.i32, i4 %tile_3, i32 3" [nn.cpp:82]   --->   Operation 81 'bitselect' 'tmp_10' <Predicate = true> <Delay = 0.00>
ST_6 : Operation 82 [1/1] (0.00ns)   --->   "%br_ln82 = br i1 %tmp_10, void %VITIS_LOOP_84_7.split, void %for.body.i.preheader" [nn.cpp:82]   --->   Operation 82 'br' 'br_ln82' <Predicate = true> <Delay = 0.00>
ST_6 : Operation 83 [2/2] (0.00ns)   --->   "%call_ln82 = call void @neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8, i10 %layer2_weight_tile, i3 %trunc_ln82, i10 %layer2_weight_tile_1, i10 %layer2_weight_tile_2, i10 %layer2_weight_tile_3, i10 %layer2_weights" [nn.cpp:82]   --->   Operation 83 'call' 'call_ln82' <Predicate = (!tmp_10)> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_6 : Operation 84 [1/1] (1.77ns)   --->   "%cmp131 = icmp_eq  i4 %tile_3, i4 0" [nn.cpp:82]   --->   Operation 84 'icmp' 'cmp131' <Predicate = (!tmp_10)> <Delay = 1.77> <CoreInst = "Cmp">   --->   Core 9 'Cmp' <Latency = 0> <II = 1> <Delay = 1.77> <FuncUnit> <Opcode : 'icmp'> <InPorts = 2> <OutPorts = 1>
ST_6 : Operation 85 [1/1] (1.77ns)   --->   "%add_ln82 = add i4 %tile_3, i4 4" [nn.cpp:82]   --->   Operation 85 'add' 'add_ln82' <Predicate = (!tmp_10)> <Delay = 1.77> <CoreInst = "Adder">   --->   Core 1 'Adder' <Latency = 0> <II = 1> <Delay = 1.77> <FuncUnit> <Opcode : 'add' 'sub'> <InPorts = 2> <OutPorts = 1>
ST_6 : Operation 86 [1/1] (1.61ns)   --->   "%store_ln82 = store i4 %add_ln82, i4 %tile_1" [nn.cpp:82]   --->   Operation 86 'store' 'store_ln82' <Predicate = (!tmp_10)> <Delay = 1.61>
ST_6 : Operation 87 [1/1] (0.00ns)   --->   "%p_0_0_0114_i1_load = load i16 %p_0_0_0114_i1"   --->   Operation 87 'load' 'p_0_0_0114_i1_load' <Predicate = (tmp_10)> <Delay = 0.00>
ST_6 : Operation 88 [1/1] (0.00ns)   --->   "%conv_i_i_le10_lcssa17_load = load i16 %conv_i_i_le10_lcssa17"   --->   Operation 88 'load' 'conv_i_i_le10_lcssa17_load' <Predicate = (tmp_10)> <Delay = 0.00>
ST_6 : Operation 89 [1/1] (0.00ns)   --->   "%conv_i_i_le12_lcssa19_load = load i16 %conv_i_i_le12_lcssa19"   --->   Operation 89 'load' 'conv_i_i_le12_lcssa19_load' <Predicate = (tmp_10)> <Delay = 0.00>
ST_6 : Operation 90 [2/2] (6.69ns)   --->   "%call_ln0 = call void @neural_network_Pipeline_VITIS_LOOP_21_1, i16 %p_0_0_0114_i1_load, i16 %conv_i_i_le10_lcssa17_load, i16 %conv_i_i_le12_lcssa19_load, i16 %max_val_loc"   --->   Operation 90 'call' 'call_ln0' <Predicate = (tmp_10)> <Delay = 6.69> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 7 <SV = 3> <Delay = 0.00>
ST_7 : Operation 91 [1/2] (0.00ns)   --->   "%call_ln82 = call void @neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8, i10 %layer2_weight_tile, i3 %trunc_ln82, i10 %layer2_weight_tile_1, i10 %layer2_weight_tile_2, i10 %layer2_weight_tile_3, i10 %layer2_weights" [nn.cpp:82]   --->   Operation 91 'call' 'call_ln82' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 8 <SV = 4> <Delay = 2.15>
ST_8 : Operation 92 [1/1] (0.00ns)   --->   "%conv_i_i_le8_lcssa15_load_1 = load i16 %conv_i_i_le8_lcssa15"   --->   Operation 92 'load' 'conv_i_i_le8_lcssa15_load_1' <Predicate = true> <Delay = 0.00>
ST_8 : Operation 93 [2/2] (2.15ns)   --->   "%call_ln82 = call void @neural_network_Pipeline_VITIS_LOOP_92_9, i16 %conv_i_i_le8_lcssa15_load_1, i10 %layer2_weight_tile, i10 %layer2_weight_tile_1, i10 %layer2_weight_tile_2, i10 %layer2_weight_tile_3, i3 %trunc_ln82, i15 %layer1_output, i15 %layer1_output_1, i15 %layer1_output_2, i15 %layer1_output_3, i1 %cmp131, i16 %conv_i_i_le12_lcssa19, i16 %conv_i_i_le10_lcssa17, i16 %conv_i_i_le8_lcssa15, i16 %p_0_0_0114_i1" [nn.cpp:82]   --->   Operation 93 'call' 'call_ln82' <Predicate = true> <Delay = 2.15> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 9 <SV = 5> <Delay = 0.00>
ST_9 : Operation 94 [1/1] (0.00ns)   --->   "%speclooptripcount_ln82 = speclooptripcount void @_ssdm_op_SpecLoopTripCount, i64 2, i64 2, i64 2" [nn.cpp:82]   --->   Operation 94 'speclooptripcount' 'speclooptripcount_ln82' <Predicate = true> <Delay = 0.00>
ST_9 : Operation 95 [1/1] (0.00ns)   --->   "%specloopname_ln82 = specloopname void @_ssdm_op_SpecLoopName, void @empty_18" [nn.cpp:82]   --->   Operation 95 'specloopname' 'specloopname_ln82' <Predicate = true> <Delay = 0.00>
ST_9 : Operation 96 [1/2] (0.00ns)   --->   "%call_ln82 = call void @neural_network_Pipeline_VITIS_LOOP_92_9, i16 %conv_i_i_le8_lcssa15_load_1, i10 %layer2_weight_tile, i10 %layer2_weight_tile_1, i10 %layer2_weight_tile_2, i10 %layer2_weight_tile_3, i3 %trunc_ln82, i15 %layer1_output, i15 %layer1_output_1, i15 %layer1_output_2, i15 %layer1_output_3, i1 %cmp131, i16 %conv_i_i_le12_lcssa19, i16 %conv_i_i_le10_lcssa17, i16 %conv_i_i_le8_lcssa15, i16 %p_0_0_0114_i1" [nn.cpp:82]   --->   Operation 96 'call' 'call_ln82' <Predicate = true> <Delay = 0.00> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_9 : Operation 97 [1/1] (0.00ns)   --->   "%br_ln82 = br void %VITIS_LOOP_84_7" [nn.cpp:82]   --->   Operation 97 'br' 'br_ln82' <Predicate = true> <Delay = 0.00>

State 10 <SV = 3> <Delay = 3.19>
ST_10 : Operation 98 [1/2] (3.19ns)   --->   "%call_ln0 = call void @neural_network_Pipeline_VITIS_LOOP_21_1, i16 %p_0_0_0114_i1_load, i16 %conv_i_i_le10_lcssa17_load, i16 %conv_i_i_le12_lcssa19_load, i16 %max_val_loc"   --->   Operation 98 'call' 'call_ln0' <Predicate = true> <Delay = 3.19> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 11 <SV = 4> <Delay = 6.89>
ST_11 : Operation 99 [1/1] (0.00ns)   --->   "%conv_i_i_le8_lcssa15_load = load i16 %conv_i_i_le8_lcssa15"   --->   Operation 99 'load' 'conv_i_i_le8_lcssa15_load' <Predicate = true> <Delay = 0.00>
ST_11 : Operation 100 [1/1] (0.00ns)   --->   "%max_val_loc_load = load i16 %max_val_loc"   --->   Operation 100 'load' 'max_val_loc_load' <Predicate = true> <Delay = 0.00>
ST_11 : Operation 101 [2/2] (6.89ns)   --->   "%call_ln0 = call void @neural_network_Pipeline_VITIS_LOOP_26_2, i16 %output_0, i16 %output_2, i16 %output_1, i16 %conv_i_i_le8_lcssa15_load, i16 %conv_i_i_le10_lcssa17_load, i16 %conv_i_i_le12_lcssa19_load, i16 %max_val_loc_load, i16 %sum_2_loc, i11 %f_x_lsb_table, i25 %exp_x_msb_2_m_1_table, i25 %exp_x_msb_1_table"   --->   Operation 101 'call' 'call_ln0' <Predicate = true> <Delay = 6.89> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 12 <SV = 5> <Delay = 6.45>
ST_12 : Operation 102 [1/2] (6.45ns)   --->   "%call_ln0 = call void @neural_network_Pipeline_VITIS_LOOP_26_2, i16 %output_0, i16 %output_2, i16 %output_1, i16 %conv_i_i_le8_lcssa15_load, i16 %conv_i_i_le10_lcssa17_load, i16 %conv_i_i_le12_lcssa19_load, i16 %max_val_loc_load, i16 %sum_2_loc, i11 %f_x_lsb_table, i25 %exp_x_msb_2_m_1_table, i25 %exp_x_msb_1_table"   --->   Operation 102 'call' 'call_ln0' <Predicate = true> <Delay = 6.45> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 13 <SV = 6> <Delay = 5.57>
ST_13 : Operation 103 [1/1] (0.00ns)   --->   "%sum_2_loc_load = load i16 %sum_2_loc"   --->   Operation 103 'load' 'sum_2_loc_load' <Predicate = true> <Delay = 0.00>
ST_13 : Operation 104 [2/2] (5.57ns)   --->   "%call_ln0 = call void @neural_network_Pipeline_VITIS_LOOP_32_3, i16 %output_0, i16 %output_2, i16 %output_1, i16 %sum_2_loc_load"   --->   Operation 104 'call' 'call_ln0' <Predicate = true> <Delay = 5.57> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >

State 14 <SV = 7> <Delay = 6.39>
ST_14 : Operation 105 [1/2] (6.39ns)   --->   "%call_ln0 = call void @neural_network_Pipeline_VITIS_LOOP_32_3, i16 %output_0, i16 %output_2, i16 %output_1, i16 %sum_2_loc_load"   --->   Operation 105 'call' 'call_ln0' <Predicate = true> <Delay = 6.39> <CoreType = "Generic">   --->   Core 0 '' <Latency = 0> <II = 1> <Delay = 1.00> <Generic> <Opcode : >
ST_14 : Operation 106 [1/1] (0.00ns)   --->   "%ret_ln104 = ret" [nn.cpp:104]   --->   Operation 106 'ret' 'ret_ln104' <Predicate = true> <Delay = 0.00>


============================================================
+ Verbose Summary: Binding
============================================================
STG Binding: 
---------------- STG Properties BEGIN ----------------
- Is combinational: 0
- Is one-state seq: 0
- Is datapath-only: 0
- Is pipelined: 0
- Is top level: 1
Port [ Return ] is wired: 1; IO mode=ap_ctrl_hs:ce=0
Port [ input_0]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=0; pingpong=0; private_global=0; IO mode=ap_none:ce=0
Port [ input_1]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=0; pingpong=0; private_global=0; IO mode=ap_none:ce=0
Port [ input_2]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=0; pingpong=0; private_global=0; IO mode=ap_none:ce=0
Port [ input_3]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=0; type=0; pingpong=0; private_global=0; IO mode=ap_none:ce=0
Port [ output_0]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=2; type=0; pingpong=0; private_global=0; IO mode=ap_ovld:ce=0
Port [ output_1]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=2; type=0; pingpong=0; private_global=0; IO mode=ap_ovld:ce=0
Port [ output_2]:  wired=1; compound=0; hidden=0; nouse=0; global=0; static=0; extern=0; dir=2; type=0; pingpong=0; private_global=0; IO mode=ap_ovld:ce=0
Port [ layer1_weights]:  wired=0; compound=1; hidden=1; nouse=1; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[1]; IO mode=ap_memory:ce=0
Port [ layer1_bias]:  wired=0; compound=1; hidden=1; nouse=1; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[1]; IO mode=ap_memory:ce=0
Port [ f_x_lsb_table]:  wired=0; compound=1; hidden=1; nouse=1; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[1]; IO mode=ap_memory:ce=0
Port [ exp_x_msb_2_m_1_table]:  wired=0; compound=1; hidden=1; nouse=1; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[1]; IO mode=ap_memory:ce=0
Port [ exp_x_msb_1_table]:  wired=0; compound=1; hidden=1; nouse=1; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[1]; IO mode=ap_memory:ce=0
Port [ layer2_weights]:  wired=0; compound=1; hidden=1; nouse=1; global=1; static=1; extern=0; dir=0; type=1; pingpong=0; private_global=0; MemPort=[1]; IO mode=ap_memory:ce=0
---------------- STG Properties END ------------------

---------------- Datapath Model BEGIN ----------------

<LifeTime>
<method=bitvector/>
tile                        (alloca           ) [ 011111000000000]
sum_2_loc                   (alloca           ) [ 001111111111110]
max_val_loc                 (alloca           ) [ 001111111111000]
spectopmodule_ln38          (spectopmodule    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specbitsmap_ln0             (specbitsmap      ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
specinterface_ln0           (specinterface    ) [ 000000000000000]
layer1_output               (alloca           ) [ 001111111100000]
layer1_output_1             (alloca           ) [ 001111111100000]
layer1_output_2             (alloca           ) [ 001111111100000]
layer1_output_3             (alloca           ) [ 001111111100000]
layer1_weight_tile          (alloca           ) [ 001111000000000]
layer1_weight_tile_1        (alloca           ) [ 001111000000000]
layer1_weight_tile_2        (alloca           ) [ 001111000000000]
layer1_weight_tile_3        (alloca           ) [ 001111000000000]
layer2_weight_tile          (alloca           ) [ 001111111100000]
layer2_weight_tile_1        (alloca           ) [ 001111111100000]
layer2_weight_tile_2        (alloca           ) [ 001111111100000]
layer2_weight_tile_3        (alloca           ) [ 001111111100000]
input_0_read                (read             ) [ 001111000000000]
input_1_read                (read             ) [ 001111000000000]
input_2_read                (read             ) [ 001111000000000]
input_3_read                (read             ) [ 001111000000000]
store_ln60                  (store            ) [ 000000000000000]
br_ln60                     (br               ) [ 000000000000000]
tile_2                      (load             ) [ 000000000000000]
tmp                         (bitselect        ) [ 001111000000000]
br_ln60                     (br               ) [ 000000000000000]
trunc_ln60                  (trunc            ) [ 000111000000000]
add_ln60                    (add              ) [ 000000000000000]
store_ln60                  (store            ) [ 000000000000000]
tile_1                      (alloca           ) [ 001111111100000]
p_0_0_0114_i1               (alloca           ) [ 000000111100000]
conv_i_i_le8_lcssa15        (alloca           ) [ 000000111111000]
conv_i_i_le10_lcssa17       (alloca           ) [ 000000111100000]
conv_i_i_le12_lcssa19       (alloca           ) [ 000000111100000]
store_ln82                  (store            ) [ 000000000000000]
br_ln82                     (br               ) [ 000000000000000]
call_ln60                   (call             ) [ 000000000000000]
speclooptripcount_ln60      (speclooptripcount) [ 000000000000000]
specloopname_ln60           (specloopname     ) [ 000000000000000]
call_ln60                   (call             ) [ 000000000000000]
br_ln60                     (br               ) [ 000000000000000]
tile_3                      (load             ) [ 000000000000000]
trunc_ln82                  (trunc            ) [ 000000011100000]
tmp_10                      (bitselect        ) [ 000000111100000]
br_ln82                     (br               ) [ 000000000000000]
cmp131                      (icmp             ) [ 000000011100000]
add_ln82                    (add              ) [ 000000000000000]
store_ln82                  (store            ) [ 000000000000000]
p_0_0_0114_i1_load          (load             ) [ 000000000010000]
conv_i_i_le10_lcssa17_load  (load             ) [ 000000000011100]
conv_i_i_le12_lcssa19_load  (load             ) [ 000000000011100]
call_ln82                   (call             ) [ 000000000000000]
conv_i_i_le8_lcssa15_load_1 (load             ) [ 000000000100000]
speclooptripcount_ln82      (speclooptripcount) [ 000000000000000]
specloopname_ln82           (specloopname     ) [ 000000000000000]
call_ln82                   (call             ) [ 000000000000000]
br_ln82                     (br               ) [ 000000000000000]
call_ln0                    (call             ) [ 000000000000000]
conv_i_i_le8_lcssa15_load   (load             ) [ 000000000000100]
max_val_loc_load            (load             ) [ 000000000000100]
call_ln0                    (call             ) [ 000000000000000]
sum_2_loc_load              (load             ) [ 000000000000001]
call_ln0                    (call             ) [ 000000000000000]
ret_ln104                   (ret              ) [ 000000000000000]
</LifeTime>

<model>

<comp_list>
<comp id="0" class="1000" name="input_0">
<pin_list>
<pin id="1" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="input_0"/></StgValue>
</bind>
</comp>

<comp id="2" class="1000" name="input_1">
<pin_list>
<pin id="3" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="input_1"/></StgValue>
</bind>
</comp>

<comp id="4" class="1000" name="input_2">
<pin_list>
<pin id="5" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="input_2"/></StgValue>
</bind>
</comp>

<comp id="6" class="1000" name="input_3">
<pin_list>
<pin id="7" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="input_3"/></StgValue>
</bind>
</comp>

<comp id="8" class="1000" name="output_0">
<pin_list>
<pin id="9" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="output_0"/></StgValue>
</bind>
</comp>

<comp id="10" class="1000" name="output_1">
<pin_list>
<pin id="11" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="output_1"/></StgValue>
</bind>
</comp>

<comp id="12" class="1000" name="output_2">
<pin_list>
<pin id="13" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="output_2"/></StgValue>
</bind>
</comp>

<comp id="14" class="1000" name="layer1_weights">
<pin_list>
<pin id="15" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="layer1_weights"/><MemPortTyVec>1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="16" class="1000" name="layer1_bias">
<pin_list>
<pin id="17" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="layer1_bias"/><MemPortTyVec>1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="18" class="1000" name="f_x_lsb_table">
<pin_list>
<pin id="19" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="f_x_lsb_table"/><MemPortTyVec>1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="20" class="1000" name="exp_x_msb_2_m_1_table">
<pin_list>
<pin id="21" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="exp_x_msb_2_m_1_table"/><MemPortTyVec>1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="22" class="1000" name="exp_x_msb_1_table">
<pin_list>
<pin id="23" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="exp_x_msb_1_table"/><MemPortTyVec>1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="24" class="1000" name="layer2_weights">
<pin_list>
<pin id="25" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="layer2_weights"/><MemPortTyVec>1 </MemPortTyVec>
</StgValue>
</bind>
</comp>

<comp id="26" class="1001" name="const_26">
<pin_list>
<pin id="27" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="28" class="1001" name="const_28">
<pin_list>
<pin id="29" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="30" class="1001" name="const_30">
<pin_list>
<pin id="31" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecTopModule"/></StgValue>
</bind>
</comp>

<comp id="32" class="1001" name="const_32">
<pin_list>
<pin id="33" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_6"/></StgValue>
</bind>
</comp>

<comp id="34" class="1001" name="const_34">
<pin_list>
<pin id="35" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecBitsMap"/></StgValue>
</bind>
</comp>

<comp id="36" class="1001" name="const_36">
<pin_list>
<pin id="37" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecInterface"/></StgValue>
</bind>
</comp>

<comp id="38" class="1001" name="const_38">
<pin_list>
<pin id="39" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_14"/></StgValue>
</bind>
</comp>

<comp id="40" class="1001" name="const_40">
<pin_list>
<pin id="41" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="42" class="1001" name="const_42">
<pin_list>
<pin id="43" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_13"/></StgValue>
</bind>
</comp>

<comp id="44" class="1001" name="const_44">
<pin_list>
<pin id="45" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_19"/></StgValue>
</bind>
</comp>

<comp id="46" class="1001" name="const_46">
<pin_list>
<pin id="47" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_12"/></StgValue>
</bind>
</comp>

<comp id="48" class="1001" name="const_48">
<pin_list>
<pin id="49" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="50" class="1001" name="const_50">
<pin_list>
<pin id="51" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_11"/></StgValue>
</bind>
</comp>

<comp id="52" class="1001" name="const_52">
<pin_list>
<pin id="53" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_10"/></StgValue>
</bind>
</comp>

<comp id="54" class="1001" name="const_54">
<pin_list>
<pin id="55" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_2"/></StgValue>
</bind>
</comp>

<comp id="56" class="1001" name="const_56">
<pin_list>
<pin id="57" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_9"/></StgValue>
</bind>
</comp>

<comp id="58" class="1001" name="const_58">
<pin_list>
<pin id="59" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_3"/></StgValue>
</bind>
</comp>

<comp id="60" class="1001" name="const_60">
<pin_list>
<pin id="61" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_8"/></StgValue>
</bind>
</comp>

<comp id="62" class="1001" name="const_62">
<pin_list>
<pin id="63" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_1"/></StgValue>
</bind>
</comp>

<comp id="64" class="1001" name="const_64">
<pin_list>
<pin id="65" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_Read.s_axilite.i16P0A"/></StgValue>
</bind>
</comp>

<comp id="66" class="1001" name="const_66">
<pin_list>
<pin id="67" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="68" class="1001" name="const_68">
<pin_list>
<pin id="69" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_BitSelect.i1.i4.i32"/></StgValue>
</bind>
</comp>

<comp id="70" class="1001" name="const_70">
<pin_list>
<pin id="71" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="72" class="1001" name="const_72">
<pin_list>
<pin id="73" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3"/></StgValue>
</bind>
</comp>

<comp id="74" class="1001" name="const_74">
<pin_list>
<pin id="75" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="76" class="1001" name="const_76">
<pin_list>
<pin id="77" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_70_4"/></StgValue>
</bind>
</comp>

<comp id="78" class="1001" name="const_78">
<pin_list>
<pin id="79" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecLoopTripCount"/></StgValue>
</bind>
</comp>

<comp id="80" class="1001" name="const_80">
<pin_list>
<pin id="81" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name=""/></StgValue>
</bind>
</comp>

<comp id="82" class="1001" name="const_82">
<pin_list>
<pin id="83" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="_ssdm_op_SpecLoopName"/></StgValue>
</bind>
</comp>

<comp id="84" class="1001" name="const_84">
<pin_list>
<pin id="85" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_15"/></StgValue>
</bind>
</comp>

<comp id="86" class="1001" name="const_86">
<pin_list>
<pin id="87" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8"/></StgValue>
</bind>
</comp>

<comp id="88" class="1001" name="const_88">
<pin_list>
<pin id="89" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_21_1"/></StgValue>
</bind>
</comp>

<comp id="90" class="1001" name="const_90">
<pin_list>
<pin id="91" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_92_9"/></StgValue>
</bind>
</comp>

<comp id="92" class="1001" name="const_92">
<pin_list>
<pin id="93" dir="1" index="0" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<StgValue><ssdm name="empty_18"/></StgValue>
</bind>
</comp>

<comp id="94" class="1001" name="const_94">
<pin_list>
<pin id="95" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_26_2"/></StgValue>
</bind>
</comp>

<comp id="96" class="1001" name="const_96">
<pin_list>
<pin id="97" dir="1" index="0" bw="1" slack="0"/>
</pin_list>
<bind>
<StgValue><ssdm name="neural_network_Pipeline_VITIS_LOOP_32_3"/></StgValue>
</bind>
</comp>

<comp id="98" class="1004" name="tile_fu_98">
<pin_list>
<pin id="99" dir="0" index="0" bw="1" slack="0"/>
<pin id="100" dir="1" index="1" bw="4" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="tile/1 "/>
</bind>
</comp>

<comp id="102" class="1004" name="sum_2_loc_fu_102">
<pin_list>
<pin id="103" dir="0" index="0" bw="1" slack="0"/>
<pin id="104" dir="1" index="1" bw="16" slack="4"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="sum_2_loc/1 "/>
</bind>
</comp>

<comp id="106" class="1004" name="max_val_loc_fu_106">
<pin_list>
<pin id="107" dir="0" index="0" bw="1" slack="0"/>
<pin id="108" dir="1" index="1" bw="16" slack="2"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="max_val_loc/1 "/>
</bind>
</comp>

<comp id="110" class="1004" name="layer1_output_alloca_fu_110">
<pin_list>
<pin id="111" dir="0" index="0" bw="1" slack="0"/>
<pin id="112" dir="1" index="1" bw="15" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_output/1 "/>
</bind>
</comp>

<comp id="114" class="1004" name="layer1_output_1_alloca_fu_114">
<pin_list>
<pin id="115" dir="0" index="0" bw="1" slack="0"/>
<pin id="116" dir="1" index="1" bw="15" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_output_1/1 "/>
</bind>
</comp>

<comp id="118" class="1004" name="layer1_output_2_alloca_fu_118">
<pin_list>
<pin id="119" dir="0" index="0" bw="1" slack="0"/>
<pin id="120" dir="1" index="1" bw="15" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_output_2/1 "/>
</bind>
</comp>

<comp id="122" class="1004" name="layer1_output_3_alloca_fu_122">
<pin_list>
<pin id="123" dir="0" index="0" bw="1" slack="0"/>
<pin id="124" dir="1" index="1" bw="15" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_output_3/1 "/>
</bind>
</comp>

<comp id="126" class="1004" name="layer1_weight_tile_alloca_fu_126">
<pin_list>
<pin id="127" dir="0" index="0" bw="1" slack="0"/>
<pin id="128" dir="1" index="1" bw="9" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_weight_tile/1 "/>
</bind>
</comp>

<comp id="130" class="1004" name="layer1_weight_tile_1_alloca_fu_130">
<pin_list>
<pin id="131" dir="0" index="0" bw="1" slack="0"/>
<pin id="132" dir="1" index="1" bw="9" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_weight_tile_1/1 "/>
</bind>
</comp>

<comp id="134" class="1004" name="layer1_weight_tile_2_alloca_fu_134">
<pin_list>
<pin id="135" dir="0" index="0" bw="1" slack="0"/>
<pin id="136" dir="1" index="1" bw="9" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_weight_tile_2/1 "/>
</bind>
</comp>

<comp id="138" class="1004" name="layer1_weight_tile_3_alloca_fu_138">
<pin_list>
<pin id="139" dir="0" index="0" bw="1" slack="0"/>
<pin id="140" dir="1" index="1" bw="9" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer1_weight_tile_3/1 "/>
</bind>
</comp>

<comp id="142" class="1004" name="layer2_weight_tile_alloca_fu_142">
<pin_list>
<pin id="143" dir="0" index="0" bw="1" slack="0"/>
<pin id="144" dir="1" index="1" bw="10" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer2_weight_tile/1 "/>
</bind>
</comp>

<comp id="146" class="1004" name="layer2_weight_tile_1_alloca_fu_146">
<pin_list>
<pin id="147" dir="0" index="0" bw="1" slack="0"/>
<pin id="148" dir="1" index="1" bw="10" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer2_weight_tile_1/1 "/>
</bind>
</comp>

<comp id="150" class="1004" name="layer2_weight_tile_2_alloca_fu_150">
<pin_list>
<pin id="151" dir="0" index="0" bw="1" slack="0"/>
<pin id="152" dir="1" index="1" bw="10" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer2_weight_tile_2/1 "/>
</bind>
</comp>

<comp id="154" class="1004" name="layer2_weight_tile_3_alloca_fu_154">
<pin_list>
<pin id="155" dir="0" index="0" bw="1" slack="0"/>
<pin id="156" dir="1" index="1" bw="10" slack="2147483647"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="layer2_weight_tile_3/1 "/>
</bind>
</comp>

<comp id="158" class="1004" name="tile_1_fu_158">
<pin_list>
<pin id="159" dir="0" index="0" bw="1" slack="0"/>
<pin id="160" dir="1" index="1" bw="4" slack="0"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="tile_1/2 "/>
</bind>
</comp>

<comp id="162" class="1004" name="p_0_0_0114_i1_fu_162">
<pin_list>
<pin id="163" dir="0" index="0" bw="1" slack="0"/>
<pin id="164" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="p_0_0_0114_i1/2 "/>
</bind>
</comp>

<comp id="166" class="1004" name="conv_i_i_le8_lcssa15_fu_166">
<pin_list>
<pin id="167" dir="0" index="0" bw="1" slack="0"/>
<pin id="168" dir="1" index="1" bw="16" slack="3"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="conv_i_i_le8_lcssa15/2 "/>
</bind>
</comp>

<comp id="170" class="1004" name="conv_i_i_le10_lcssa17_fu_170">
<pin_list>
<pin id="171" dir="0" index="0" bw="1" slack="0"/>
<pin id="172" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="conv_i_i_le10_lcssa17/2 "/>
</bind>
</comp>

<comp id="174" class="1004" name="conv_i_i_le12_lcssa19_fu_174">
<pin_list>
<pin id="175" dir="0" index="0" bw="1" slack="0"/>
<pin id="176" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opcode="alloca(26) " fcode="alloca"/>
<opset="conv_i_i_le12_lcssa19/2 "/>
</bind>
</comp>

<comp id="178" class="1004" name="input_0_read_read_fu_178">
<pin_list>
<pin id="179" dir="0" index="0" bw="16" slack="0"/>
<pin id="180" dir="0" index="1" bw="16" slack="0"/>
<pin id="181" dir="1" index="2" bw="16" slack="3"/>
</pin_list>
<bind>
<opcode="read(1150) " fcode="read"/>
<opset="input_0_read/1 "/>
</bind>
</comp>

<comp id="184" class="1004" name="input_1_read_read_fu_184">
<pin_list>
<pin id="185" dir="0" index="0" bw="16" slack="0"/>
<pin id="186" dir="0" index="1" bw="16" slack="0"/>
<pin id="187" dir="1" index="2" bw="16" slack="3"/>
</pin_list>
<bind>
<opcode="read(1150) " fcode="read"/>
<opset="input_1_read/1 "/>
</bind>
</comp>

<comp id="190" class="1004" name="input_2_read_read_fu_190">
<pin_list>
<pin id="191" dir="0" index="0" bw="16" slack="0"/>
<pin id="192" dir="0" index="1" bw="16" slack="0"/>
<pin id="193" dir="1" index="2" bw="16" slack="3"/>
</pin_list>
<bind>
<opcode="read(1150) " fcode="read"/>
<opset="input_2_read/1 "/>
</bind>
</comp>

<comp id="196" class="1004" name="input_3_read_read_fu_196">
<pin_list>
<pin id="197" dir="0" index="0" bw="16" slack="0"/>
<pin id="198" dir="0" index="1" bw="16" slack="0"/>
<pin id="199" dir="1" index="2" bw="16" slack="3"/>
</pin_list>
<bind>
<opcode="read(1150) " fcode="read"/>
<opset="input_3_read/1 "/>
</bind>
</comp>

<comp id="202" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3_fu_202">
<pin_list>
<pin id="203" dir="0" index="0" bw="0" slack="0"/>
<pin id="204" dir="0" index="1" bw="9" slack="2147483647"/>
<pin id="205" dir="0" index="2" bw="3" slack="0"/>
<pin id="206" dir="0" index="3" bw="9" slack="2147483647"/>
<pin id="207" dir="0" index="4" bw="9" slack="2147483647"/>
<pin id="208" dir="0" index="5" bw="9" slack="2147483647"/>
<pin id="209" dir="0" index="6" bw="9" slack="0"/>
<pin id="210" dir="1" index="7" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln60/2 "/>
</bind>
</comp>

<comp id="213" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_70_4_fu_213">
<pin_list>
<pin id="214" dir="0" index="0" bw="0" slack="0"/>
<pin id="215" dir="0" index="1" bw="15" slack="2147483647"/>
<pin id="216" dir="0" index="2" bw="15" slack="2147483647"/>
<pin id="217" dir="0" index="3" bw="15" slack="2147483647"/>
<pin id="218" dir="0" index="4" bw="15" slack="2147483647"/>
<pin id="219" dir="0" index="5" bw="3" slack="2"/>
<pin id="220" dir="0" index="6" bw="9" slack="2147483647"/>
<pin id="221" dir="0" index="7" bw="16" slack="3"/>
<pin id="222" dir="0" index="8" bw="9" slack="2147483647"/>
<pin id="223" dir="0" index="9" bw="16" slack="3"/>
<pin id="224" dir="0" index="10" bw="9" slack="2147483647"/>
<pin id="225" dir="0" index="11" bw="16" slack="3"/>
<pin id="226" dir="0" index="12" bw="9" slack="2147483647"/>
<pin id="227" dir="0" index="13" bw="16" slack="3"/>
<pin id="228" dir="0" index="14" bw="7" slack="0"/>
<pin id="229" dir="1" index="15" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln60/4 "/>
</bind>
</comp>

<comp id="232" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8_fu_232">
<pin_list>
<pin id="233" dir="0" index="0" bw="0" slack="0"/>
<pin id="234" dir="0" index="1" bw="10" slack="2147483647"/>
<pin id="235" dir="0" index="2" bw="3" slack="0"/>
<pin id="236" dir="0" index="3" bw="10" slack="2147483647"/>
<pin id="237" dir="0" index="4" bw="10" slack="2147483647"/>
<pin id="238" dir="0" index="5" bw="10" slack="2147483647"/>
<pin id="239" dir="0" index="6" bw="10" slack="0"/>
<pin id="240" dir="1" index="7" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln82/6 "/>
</bind>
</comp>

<comp id="243" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_21_1_fu_243">
<pin_list>
<pin id="244" dir="0" index="0" bw="0" slack="0"/>
<pin id="245" dir="0" index="1" bw="16" slack="0"/>
<pin id="246" dir="0" index="2" bw="16" slack="0"/>
<pin id="247" dir="0" index="3" bw="16" slack="0"/>
<pin id="248" dir="0" index="4" bw="16" slack="2"/>
<pin id="249" dir="1" index="5" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/6 "/>
</bind>
</comp>

<comp id="251" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_92_9_fu_251">
<pin_list>
<pin id="252" dir="0" index="0" bw="0" slack="0"/>
<pin id="253" dir="0" index="1" bw="16" slack="0"/>
<pin id="254" dir="0" index="2" bw="10" slack="2147483647"/>
<pin id="255" dir="0" index="3" bw="10" slack="2147483647"/>
<pin id="256" dir="0" index="4" bw="10" slack="2147483647"/>
<pin id="257" dir="0" index="5" bw="10" slack="2147483647"/>
<pin id="258" dir="0" index="6" bw="3" slack="2"/>
<pin id="259" dir="0" index="7" bw="15" slack="2147483647"/>
<pin id="260" dir="0" index="8" bw="15" slack="2147483647"/>
<pin id="261" dir="0" index="9" bw="15" slack="2147483647"/>
<pin id="262" dir="0" index="10" bw="15" slack="2147483647"/>
<pin id="263" dir="0" index="11" bw="1" slack="2"/>
<pin id="264" dir="0" index="12" bw="16" slack="3"/>
<pin id="265" dir="0" index="13" bw="16" slack="3"/>
<pin id="266" dir="0" index="14" bw="16" slack="3"/>
<pin id="267" dir="0" index="15" bw="16" slack="3"/>
<pin id="268" dir="1" index="16" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln82/8 "/>
</bind>
</comp>

<comp id="270" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_26_2_fu_270">
<pin_list>
<pin id="271" dir="0" index="0" bw="0" slack="0"/>
<pin id="272" dir="0" index="1" bw="16" slack="0"/>
<pin id="273" dir="0" index="2" bw="16" slack="0"/>
<pin id="274" dir="0" index="3" bw="16" slack="0"/>
<pin id="275" dir="0" index="4" bw="16" slack="0"/>
<pin id="276" dir="0" index="5" bw="16" slack="2"/>
<pin id="277" dir="0" index="6" bw="16" slack="2"/>
<pin id="278" dir="0" index="7" bw="16" slack="0"/>
<pin id="279" dir="0" index="8" bw="16" slack="4"/>
<pin id="280" dir="0" index="9" bw="11" slack="0"/>
<pin id="281" dir="0" index="10" bw="25" slack="0"/>
<pin id="282" dir="0" index="11" bw="25" slack="0"/>
<pin id="283" dir="1" index="12" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/11 "/>
</bind>
</comp>

<comp id="291" class="1004" name="grp_neural_network_Pipeline_VITIS_LOOP_32_3_fu_291">
<pin_list>
<pin id="292" dir="0" index="0" bw="0" slack="0"/>
<pin id="293" dir="0" index="1" bw="16" slack="0"/>
<pin id="294" dir="0" index="2" bw="16" slack="0"/>
<pin id="295" dir="0" index="3" bw="16" slack="0"/>
<pin id="296" dir="0" index="4" bw="16" slack="0"/>
<pin id="297" dir="1" index="5" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="call(48) " fcode="call"/>
<opset="call_ln0/13 "/>
</bind>
</comp>

<comp id="302" class="1004" name="grp_load_fu_302">
<pin_list>
<pin id="303" dir="0" index="0" bw="16" slack="3"/>
<pin id="304" dir="1" index="1" bw="16" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="conv_i_i_le8_lcssa15_load_1/8 conv_i_i_le8_lcssa15_load/11 "/>
</bind>
</comp>

<comp id="307" class="1005" name="reg_307">
<pin_list>
<pin id="308" dir="0" index="0" bw="16" slack="1"/>
<pin id="309" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="conv_i_i_le8_lcssa15_load_1 conv_i_i_le8_lcssa15_load "/>
</bind>
</comp>

<comp id="313" class="1004" name="store_ln60_store_fu_313">
<pin_list>
<pin id="314" dir="0" index="0" bw="1" slack="0"/>
<pin id="315" dir="0" index="1" bw="4" slack="0"/>
<pin id="316" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="store(28) " fcode="store"/>
<opset="store_ln60/1 "/>
</bind>
</comp>

<comp id="318" class="1004" name="tile_2_load_fu_318">
<pin_list>
<pin id="319" dir="0" index="0" bw="4" slack="1"/>
<pin id="320" dir="1" index="1" bw="4" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="tile_2/2 "/>
</bind>
</comp>

<comp id="321" class="1004" name="tmp_fu_321">
<pin_list>
<pin id="322" dir="0" index="0" bw="1" slack="0"/>
<pin id="323" dir="0" index="1" bw="4" slack="0"/>
<pin id="324" dir="0" index="2" bw="3" slack="0"/>
<pin id="325" dir="1" index="3" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<opcode="bitselect(1000) " fcode="bitselect"/>
<opset="tmp/2 "/>
</bind>
</comp>

<comp id="329" class="1004" name="trunc_ln60_fu_329">
<pin_list>
<pin id="330" dir="0" index="0" bw="4" slack="0"/>
<pin id="331" dir="1" index="1" bw="3" slack="0"/>
</pin_list>
<bind>
<opcode="trunc(33) " fcode="trunc"/>
<opset="trunc_ln60/2 "/>
</bind>
</comp>

<comp id="334" class="1004" name="add_ln60_fu_334">
<pin_list>
<pin id="335" dir="0" index="0" bw="4" slack="0"/>
<pin id="336" dir="0" index="1" bw="4" slack="0"/>
<pin id="337" dir="1" index="2" bw="4" slack="0"/>
</pin_list>
<bind>
<opcode="add(8) " fcode="add"/>
<opset="add_ln60/2 "/>
</bind>
</comp>

<comp id="340" class="1004" name="store_ln60_store_fu_340">
<pin_list>
<pin id="341" dir="0" index="0" bw="4" slack="0"/>
<pin id="342" dir="0" index="1" bw="4" slack="1"/>
<pin id="343" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="store(28) " fcode="store"/>
<opset="store_ln60/2 "/>
</bind>
</comp>

<comp id="345" class="1004" name="store_ln82_store_fu_345">
<pin_list>
<pin id="346" dir="0" index="0" bw="1" slack="0"/>
<pin id="347" dir="0" index="1" bw="4" slack="0"/>
<pin id="348" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="store(28) " fcode="store"/>
<opset="store_ln82/2 "/>
</bind>
</comp>

<comp id="350" class="1004" name="tile_3_load_fu_350">
<pin_list>
<pin id="351" dir="0" index="0" bw="4" slack="1"/>
<pin id="352" dir="1" index="1" bw="4" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="tile_3/6 "/>
</bind>
</comp>

<comp id="353" class="1004" name="trunc_ln82_fu_353">
<pin_list>
<pin id="354" dir="0" index="0" bw="4" slack="0"/>
<pin id="355" dir="1" index="1" bw="3" slack="0"/>
</pin_list>
<bind>
<opcode="trunc(33) " fcode="trunc"/>
<opset="trunc_ln82/6 "/>
</bind>
</comp>

<comp id="358" class="1004" name="tmp_10_fu_358">
<pin_list>
<pin id="359" dir="0" index="0" bw="1" slack="0"/>
<pin id="360" dir="0" index="1" bw="4" slack="0"/>
<pin id="361" dir="0" index="2" bw="3" slack="0"/>
<pin id="362" dir="1" index="3" bw="1" slack="2147483647"/>
</pin_list>
<bind>
<opcode="bitselect(1000) " fcode="bitselect"/>
<opset="tmp_10/6 "/>
</bind>
</comp>

<comp id="366" class="1004" name="cmp131_fu_366">
<pin_list>
<pin id="367" dir="0" index="0" bw="4" slack="0"/>
<pin id="368" dir="0" index="1" bw="1" slack="0"/>
<pin id="369" dir="1" index="2" bw="1" slack="2"/>
</pin_list>
<bind>
<opcode="icmp(45) " fcode="icmp"/>
<opset="cmp131/6 "/>
</bind>
</comp>

<comp id="372" class="1004" name="add_ln82_fu_372">
<pin_list>
<pin id="373" dir="0" index="0" bw="4" slack="0"/>
<pin id="374" dir="0" index="1" bw="4" slack="0"/>
<pin id="375" dir="1" index="2" bw="4" slack="0"/>
</pin_list>
<bind>
<opcode="add(8) " fcode="add"/>
<opset="add_ln82/6 "/>
</bind>
</comp>

<comp id="378" class="1004" name="store_ln82_store_fu_378">
<pin_list>
<pin id="379" dir="0" index="0" bw="4" slack="0"/>
<pin id="380" dir="0" index="1" bw="4" slack="1"/>
<pin id="381" dir="1" index="2" bw="0" slack="2147483647"/>
</pin_list>
<bind>
<opcode="store(28) " fcode="store"/>
<opset="store_ln82/6 "/>
</bind>
</comp>

<comp id="383" class="1004" name="p_0_0_0114_i1_load_load_fu_383">
<pin_list>
<pin id="384" dir="0" index="0" bw="16" slack="1"/>
<pin id="385" dir="1" index="1" bw="16" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="p_0_0_0114_i1_load/6 "/>
</bind>
</comp>

<comp id="387" class="1004" name="conv_i_i_le10_lcssa17_load_load_fu_387">
<pin_list>
<pin id="388" dir="0" index="0" bw="16" slack="1"/>
<pin id="389" dir="1" index="1" bw="16" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="conv_i_i_le10_lcssa17_load/6 "/>
</bind>
</comp>

<comp id="391" class="1004" name="conv_i_i_le12_lcssa19_load_load_fu_391">
<pin_list>
<pin id="392" dir="0" index="0" bw="16" slack="1"/>
<pin id="393" dir="1" index="1" bw="16" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="conv_i_i_le12_lcssa19_load/6 "/>
</bind>
</comp>

<comp id="395" class="1004" name="max_val_loc_load_load_fu_395">
<pin_list>
<pin id="396" dir="0" index="0" bw="16" slack="4"/>
<pin id="397" dir="1" index="1" bw="16" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="max_val_loc_load/11 "/>
</bind>
</comp>

<comp id="399" class="1004" name="sum_2_loc_load_load_fu_399">
<pin_list>
<pin id="400" dir="0" index="0" bw="16" slack="6"/>
<pin id="401" dir="1" index="1" bw="16" slack="0"/>
</pin_list>
<bind>
<opcode="load(27) " fcode="load"/>
<opset="sum_2_loc_load/13 "/>
</bind>
</comp>

<comp id="403" class="1005" name="tile_reg_403">
<pin_list>
<pin id="404" dir="0" index="0" bw="4" slack="0"/>
<pin id="405" dir="1" index="1" bw="4" slack="0"/>
</pin_list>
<bind>
<opset="tile "/>
</bind>
</comp>

<comp id="410" class="1005" name="sum_2_loc_reg_410">
<pin_list>
<pin id="411" dir="0" index="0" bw="16" slack="4"/>
<pin id="412" dir="1" index="1" bw="16" slack="4"/>
</pin_list>
<bind>
<opset="sum_2_loc "/>
</bind>
</comp>

<comp id="416" class="1005" name="max_val_loc_reg_416">
<pin_list>
<pin id="417" dir="0" index="0" bw="16" slack="2"/>
<pin id="418" dir="1" index="1" bw="16" slack="2"/>
</pin_list>
<bind>
<opset="max_val_loc "/>
</bind>
</comp>

<comp id="422" class="1005" name="input_0_read_reg_422">
<pin_list>
<pin id="423" dir="0" index="0" bw="16" slack="3"/>
<pin id="424" dir="1" index="1" bw="16" slack="3"/>
</pin_list>
<bind>
<opset="input_0_read "/>
</bind>
</comp>

<comp id="427" class="1005" name="input_1_read_reg_427">
<pin_list>
<pin id="428" dir="0" index="0" bw="16" slack="3"/>
<pin id="429" dir="1" index="1" bw="16" slack="3"/>
</pin_list>
<bind>
<opset="input_1_read "/>
</bind>
</comp>

<comp id="432" class="1005" name="input_2_read_reg_432">
<pin_list>
<pin id="433" dir="0" index="0" bw="16" slack="3"/>
<pin id="434" dir="1" index="1" bw="16" slack="3"/>
</pin_list>
<bind>
<opset="input_2_read "/>
</bind>
</comp>

<comp id="437" class="1005" name="input_3_read_reg_437">
<pin_list>
<pin id="438" dir="0" index="0" bw="16" slack="3"/>
<pin id="439" dir="1" index="1" bw="16" slack="3"/>
</pin_list>
<bind>
<opset="input_3_read "/>
</bind>
</comp>

<comp id="445" class="1005" name="trunc_ln60_reg_445">
<pin_list>
<pin id="446" dir="0" index="0" bw="3" slack="1"/>
<pin id="447" dir="1" index="1" bw="3" slack="1"/>
</pin_list>
<bind>
<opset="trunc_ln60 "/>
</bind>
</comp>

<comp id="451" class="1005" name="tile_1_reg_451">
<pin_list>
<pin id="452" dir="0" index="0" bw="4" slack="0"/>
<pin id="453" dir="1" index="1" bw="4" slack="0"/>
</pin_list>
<bind>
<opset="tile_1 "/>
</bind>
</comp>

<comp id="458" class="1005" name="p_0_0_0114_i1_reg_458">
<pin_list>
<pin id="459" dir="0" index="0" bw="16" slack="1"/>
<pin id="460" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="p_0_0_0114_i1 "/>
</bind>
</comp>

<comp id="464" class="1005" name="conv_i_i_le8_lcssa15_reg_464">
<pin_list>
<pin id="465" dir="0" index="0" bw="16" slack="3"/>
<pin id="466" dir="1" index="1" bw="16" slack="3"/>
</pin_list>
<bind>
<opset="conv_i_i_le8_lcssa15 "/>
</bind>
</comp>

<comp id="470" class="1005" name="conv_i_i_le10_lcssa17_reg_470">
<pin_list>
<pin id="471" dir="0" index="0" bw="16" slack="1"/>
<pin id="472" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="conv_i_i_le10_lcssa17 "/>
</bind>
</comp>

<comp id="476" class="1005" name="conv_i_i_le12_lcssa19_reg_476">
<pin_list>
<pin id="477" dir="0" index="0" bw="16" slack="1"/>
<pin id="478" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="conv_i_i_le12_lcssa19 "/>
</bind>
</comp>

<comp id="482" class="1005" name="trunc_ln82_reg_482">
<pin_list>
<pin id="483" dir="0" index="0" bw="3" slack="1"/>
<pin id="484" dir="1" index="1" bw="3" slack="1"/>
</pin_list>
<bind>
<opset="trunc_ln82 "/>
</bind>
</comp>

<comp id="491" class="1005" name="cmp131_reg_491">
<pin_list>
<pin id="492" dir="0" index="0" bw="1" slack="2"/>
<pin id="493" dir="1" index="1" bw="1" slack="2"/>
</pin_list>
<bind>
<opset="cmp131 "/>
</bind>
</comp>

<comp id="496" class="1005" name="p_0_0_0114_i1_load_reg_496">
<pin_list>
<pin id="497" dir="0" index="0" bw="16" slack="1"/>
<pin id="498" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="p_0_0_0114_i1_load "/>
</bind>
</comp>

<comp id="501" class="1005" name="conv_i_i_le10_lcssa17_load_reg_501">
<pin_list>
<pin id="502" dir="0" index="0" bw="16" slack="1"/>
<pin id="503" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="conv_i_i_le10_lcssa17_load "/>
</bind>
</comp>

<comp id="507" class="1005" name="conv_i_i_le12_lcssa19_load_reg_507">
<pin_list>
<pin id="508" dir="0" index="0" bw="16" slack="1"/>
<pin id="509" dir="1" index="1" bw="16" slack="1"/>
</pin_list>
<bind>
<opset="conv_i_i_le12_lcssa19_load "/>
</bind>
</comp>

</comp_list>

<net_list>
<net id="101"><net_src comp="26" pin="0"/><net_sink comp="98" pin=0"/></net>

<net id="105"><net_src comp="28" pin="0"/><net_sink comp="102" pin=0"/></net>

<net id="109"><net_src comp="28" pin="0"/><net_sink comp="106" pin=0"/></net>

<net id="113"><net_src comp="28" pin="0"/><net_sink comp="110" pin=0"/></net>

<net id="117"><net_src comp="28" pin="0"/><net_sink comp="114" pin=0"/></net>

<net id="121"><net_src comp="28" pin="0"/><net_sink comp="118" pin=0"/></net>

<net id="125"><net_src comp="28" pin="0"/><net_sink comp="122" pin=0"/></net>

<net id="129"><net_src comp="28" pin="0"/><net_sink comp="126" pin=0"/></net>

<net id="133"><net_src comp="28" pin="0"/><net_sink comp="130" pin=0"/></net>

<net id="137"><net_src comp="28" pin="0"/><net_sink comp="134" pin=0"/></net>

<net id="141"><net_src comp="28" pin="0"/><net_sink comp="138" pin=0"/></net>

<net id="145"><net_src comp="28" pin="0"/><net_sink comp="142" pin=0"/></net>

<net id="149"><net_src comp="28" pin="0"/><net_sink comp="146" pin=0"/></net>

<net id="153"><net_src comp="28" pin="0"/><net_sink comp="150" pin=0"/></net>

<net id="157"><net_src comp="28" pin="0"/><net_sink comp="154" pin=0"/></net>

<net id="161"><net_src comp="26" pin="0"/><net_sink comp="158" pin=0"/></net>

<net id="165"><net_src comp="26" pin="0"/><net_sink comp="162" pin=0"/></net>

<net id="169"><net_src comp="26" pin="0"/><net_sink comp="166" pin=0"/></net>

<net id="173"><net_src comp="26" pin="0"/><net_sink comp="170" pin=0"/></net>

<net id="177"><net_src comp="26" pin="0"/><net_sink comp="174" pin=0"/></net>

<net id="182"><net_src comp="64" pin="0"/><net_sink comp="178" pin=0"/></net>

<net id="183"><net_src comp="0" pin="0"/><net_sink comp="178" pin=1"/></net>

<net id="188"><net_src comp="64" pin="0"/><net_sink comp="184" pin=0"/></net>

<net id="189"><net_src comp="2" pin="0"/><net_sink comp="184" pin=1"/></net>

<net id="194"><net_src comp="64" pin="0"/><net_sink comp="190" pin=0"/></net>

<net id="195"><net_src comp="4" pin="0"/><net_sink comp="190" pin=1"/></net>

<net id="200"><net_src comp="64" pin="0"/><net_sink comp="196" pin=0"/></net>

<net id="201"><net_src comp="6" pin="0"/><net_sink comp="196" pin=1"/></net>

<net id="211"><net_src comp="72" pin="0"/><net_sink comp="202" pin=0"/></net>

<net id="212"><net_src comp="14" pin="0"/><net_sink comp="202" pin=6"/></net>

<net id="230"><net_src comp="76" pin="0"/><net_sink comp="213" pin=0"/></net>

<net id="231"><net_src comp="16" pin="0"/><net_sink comp="213" pin=14"/></net>

<net id="241"><net_src comp="86" pin="0"/><net_sink comp="232" pin=0"/></net>

<net id="242"><net_src comp="24" pin="0"/><net_sink comp="232" pin=6"/></net>

<net id="250"><net_src comp="88" pin="0"/><net_sink comp="243" pin=0"/></net>

<net id="269"><net_src comp="90" pin="0"/><net_sink comp="251" pin=0"/></net>

<net id="284"><net_src comp="94" pin="0"/><net_sink comp="270" pin=0"/></net>

<net id="285"><net_src comp="8" pin="0"/><net_sink comp="270" pin=1"/></net>

<net id="286"><net_src comp="12" pin="0"/><net_sink comp="270" pin=2"/></net>

<net id="287"><net_src comp="10" pin="0"/><net_sink comp="270" pin=3"/></net>

<net id="288"><net_src comp="18" pin="0"/><net_sink comp="270" pin=9"/></net>

<net id="289"><net_src comp="20" pin="0"/><net_sink comp="270" pin=10"/></net>

<net id="290"><net_src comp="22" pin="0"/><net_sink comp="270" pin=11"/></net>

<net id="298"><net_src comp="96" pin="0"/><net_sink comp="291" pin=0"/></net>

<net id="299"><net_src comp="8" pin="0"/><net_sink comp="291" pin=1"/></net>

<net id="300"><net_src comp="12" pin="0"/><net_sink comp="291" pin=2"/></net>

<net id="301"><net_src comp="10" pin="0"/><net_sink comp="291" pin=3"/></net>

<net id="305"><net_src comp="302" pin="1"/><net_sink comp="251" pin=1"/></net>

<net id="306"><net_src comp="302" pin="1"/><net_sink comp="270" pin=4"/></net>

<net id="310"><net_src comp="302" pin="1"/><net_sink comp="307" pin=0"/></net>

<net id="311"><net_src comp="307" pin="1"/><net_sink comp="251" pin=1"/></net>

<net id="312"><net_src comp="307" pin="1"/><net_sink comp="270" pin=4"/></net>

<net id="317"><net_src comp="66" pin="0"/><net_sink comp="313" pin=0"/></net>

<net id="326"><net_src comp="68" pin="0"/><net_sink comp="321" pin=0"/></net>

<net id="327"><net_src comp="318" pin="1"/><net_sink comp="321" pin=1"/></net>

<net id="328"><net_src comp="70" pin="0"/><net_sink comp="321" pin=2"/></net>

<net id="332"><net_src comp="318" pin="1"/><net_sink comp="329" pin=0"/></net>

<net id="333"><net_src comp="329" pin="1"/><net_sink comp="202" pin=2"/></net>

<net id="338"><net_src comp="318" pin="1"/><net_sink comp="334" pin=0"/></net>

<net id="339"><net_src comp="74" pin="0"/><net_sink comp="334" pin=1"/></net>

<net id="344"><net_src comp="334" pin="2"/><net_sink comp="340" pin=0"/></net>

<net id="349"><net_src comp="66" pin="0"/><net_sink comp="345" pin=0"/></net>

<net id="356"><net_src comp="350" pin="1"/><net_sink comp="353" pin=0"/></net>

<net id="357"><net_src comp="353" pin="1"/><net_sink comp="232" pin=2"/></net>

<net id="363"><net_src comp="68" pin="0"/><net_sink comp="358" pin=0"/></net>

<net id="364"><net_src comp="350" pin="1"/><net_sink comp="358" pin=1"/></net>

<net id="365"><net_src comp="70" pin="0"/><net_sink comp="358" pin=2"/></net>

<net id="370"><net_src comp="350" pin="1"/><net_sink comp="366" pin=0"/></net>

<net id="371"><net_src comp="66" pin="0"/><net_sink comp="366" pin=1"/></net>

<net id="376"><net_src comp="350" pin="1"/><net_sink comp="372" pin=0"/></net>

<net id="377"><net_src comp="74" pin="0"/><net_sink comp="372" pin=1"/></net>

<net id="382"><net_src comp="372" pin="2"/><net_sink comp="378" pin=0"/></net>

<net id="386"><net_src comp="383" pin="1"/><net_sink comp="243" pin=1"/></net>

<net id="390"><net_src comp="387" pin="1"/><net_sink comp="243" pin=2"/></net>

<net id="394"><net_src comp="391" pin="1"/><net_sink comp="243" pin=3"/></net>

<net id="398"><net_src comp="395" pin="1"/><net_sink comp="270" pin=7"/></net>

<net id="402"><net_src comp="399" pin="1"/><net_sink comp="291" pin=4"/></net>

<net id="406"><net_src comp="98" pin="1"/><net_sink comp="403" pin=0"/></net>

<net id="407"><net_src comp="403" pin="1"/><net_sink comp="313" pin=1"/></net>

<net id="408"><net_src comp="403" pin="1"/><net_sink comp="318" pin=0"/></net>

<net id="409"><net_src comp="403" pin="1"/><net_sink comp="340" pin=1"/></net>

<net id="413"><net_src comp="102" pin="1"/><net_sink comp="410" pin=0"/></net>

<net id="414"><net_src comp="410" pin="1"/><net_sink comp="270" pin=8"/></net>

<net id="415"><net_src comp="410" pin="1"/><net_sink comp="399" pin=0"/></net>

<net id="419"><net_src comp="106" pin="1"/><net_sink comp="416" pin=0"/></net>

<net id="420"><net_src comp="416" pin="1"/><net_sink comp="243" pin=4"/></net>

<net id="421"><net_src comp="416" pin="1"/><net_sink comp="395" pin=0"/></net>

<net id="425"><net_src comp="178" pin="2"/><net_sink comp="422" pin=0"/></net>

<net id="426"><net_src comp="422" pin="1"/><net_sink comp="213" pin=7"/></net>

<net id="430"><net_src comp="184" pin="2"/><net_sink comp="427" pin=0"/></net>

<net id="431"><net_src comp="427" pin="1"/><net_sink comp="213" pin=9"/></net>

<net id="435"><net_src comp="190" pin="2"/><net_sink comp="432" pin=0"/></net>

<net id="436"><net_src comp="432" pin="1"/><net_sink comp="213" pin=11"/></net>

<net id="440"><net_src comp="196" pin="2"/><net_sink comp="437" pin=0"/></net>

<net id="441"><net_src comp="437" pin="1"/><net_sink comp="213" pin=13"/></net>

<net id="448"><net_src comp="329" pin="1"/><net_sink comp="445" pin=0"/></net>

<net id="449"><net_src comp="445" pin="1"/><net_sink comp="202" pin=2"/></net>

<net id="450"><net_src comp="445" pin="1"/><net_sink comp="213" pin=5"/></net>

<net id="454"><net_src comp="158" pin="1"/><net_sink comp="451" pin=0"/></net>

<net id="455"><net_src comp="451" pin="1"/><net_sink comp="345" pin=1"/></net>

<net id="456"><net_src comp="451" pin="1"/><net_sink comp="350" pin=0"/></net>

<net id="457"><net_src comp="451" pin="1"/><net_sink comp="378" pin=1"/></net>

<net id="461"><net_src comp="162" pin="1"/><net_sink comp="458" pin=0"/></net>

<net id="462"><net_src comp="458" pin="1"/><net_sink comp="383" pin=0"/></net>

<net id="463"><net_src comp="458" pin="1"/><net_sink comp="251" pin=15"/></net>

<net id="467"><net_src comp="166" pin="1"/><net_sink comp="464" pin=0"/></net>

<net id="468"><net_src comp="464" pin="1"/><net_sink comp="302" pin=0"/></net>

<net id="469"><net_src comp="464" pin="1"/><net_sink comp="251" pin=14"/></net>

<net id="473"><net_src comp="170" pin="1"/><net_sink comp="470" pin=0"/></net>

<net id="474"><net_src comp="470" pin="1"/><net_sink comp="387" pin=0"/></net>

<net id="475"><net_src comp="470" pin="1"/><net_sink comp="251" pin=13"/></net>

<net id="479"><net_src comp="174" pin="1"/><net_sink comp="476" pin=0"/></net>

<net id="480"><net_src comp="476" pin="1"/><net_sink comp="391" pin=0"/></net>

<net id="481"><net_src comp="476" pin="1"/><net_sink comp="251" pin=12"/></net>

<net id="485"><net_src comp="353" pin="1"/><net_sink comp="482" pin=0"/></net>

<net id="486"><net_src comp="482" pin="1"/><net_sink comp="232" pin=2"/></net>

<net id="487"><net_src comp="482" pin="1"/><net_sink comp="251" pin=6"/></net>

<net id="494"><net_src comp="366" pin="2"/><net_sink comp="491" pin=0"/></net>

<net id="495"><net_src comp="491" pin="1"/><net_sink comp="251" pin=11"/></net>

<net id="499"><net_src comp="383" pin="1"/><net_sink comp="496" pin=0"/></net>

<net id="500"><net_src comp="496" pin="1"/><net_sink comp="243" pin=1"/></net>

<net id="504"><net_src comp="387" pin="1"/><net_sink comp="501" pin=0"/></net>

<net id="505"><net_src comp="501" pin="1"/><net_sink comp="243" pin=2"/></net>

<net id="506"><net_src comp="501" pin="1"/><net_sink comp="270" pin=5"/></net>

<net id="510"><net_src comp="391" pin="1"/><net_sink comp="507" pin=0"/></net>

<net id="511"><net_src comp="507" pin="1"/><net_sink comp="243" pin=3"/></net>

<net id="512"><net_src comp="507" pin="1"/><net_sink comp="270" pin=6"/></net>

</net_list>

</model> 
---------------- Datapath Model END ------------------

* FSMD analyzer results:
  - Output states:
	Port: output_0 | {11 12 13 14 }
	Port: output_1 | {11 12 13 14 }
	Port: output_2 | {11 12 13 14 }
 - Input state : 
	Port: neural_network : input_0 | {1 }
	Port: neural_network : input_1 | {1 }
	Port: neural_network : input_2 | {1 }
	Port: neural_network : input_3 | {1 }
	Port: neural_network : output_0 | {13 14 }
	Port: neural_network : output_1 | {13 14 }
	Port: neural_network : output_2 | {13 14 }
	Port: neural_network : layer1_weights | {2 3 }
	Port: neural_network : layer1_bias | {4 5 }
	Port: neural_network : f_x_lsb_table | {11 12 }
	Port: neural_network : exp_x_msb_2_m_1_table | {11 12 }
	Port: neural_network : exp_x_msb_1_table | {11 12 }
	Port: neural_network : layer2_weights | {6 7 }
  - Chain level:
	State 1
		store_ln60 : 1
	State 2
		tmp : 1
		br_ln60 : 2
		trunc_ln60 : 1
		call_ln60 : 2
		add_ln60 : 1
		store_ln60 : 2
		store_ln82 : 1
	State 3
	State 4
	State 5
	State 6
		trunc_ln82 : 1
		tmp_10 : 1
		br_ln82 : 2
		call_ln82 : 2
		cmp131 : 1
		add_ln82 : 1
		store_ln82 : 2
		call_ln0 : 1
	State 7
	State 8
		call_ln82 : 1
	State 9
	State 10
	State 11
		call_ln0 : 1
	State 12
	State 13
		call_ln0 : 1
	State 14


============================================================
+ Verbose Summary: Datapath Resource usage 
============================================================

* Functional unit list:
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
| Operation|                           Functional Unit                          |   DSP   |  Delay  |    FF   |   LUT   |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|          | grp_neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3_fu_202 |    0    |   1.61  |   153   |   219   |
|          |         grp_neural_network_Pipeline_VITIS_LOOP_70_4_fu_213         |    4    | 12.9773 |   385   |   206   |
|          | grp_neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8_fu_232 |    0    |   1.61  |   150   |   267   |
|   call   |         grp_neural_network_Pipeline_VITIS_LOOP_21_1_fu_243         |    0    |    0    |    18   |    72   |
|          |         grp_neural_network_Pipeline_VITIS_LOOP_92_9_fu_251         |    4    | 25.8897 |   445   |   296   |
|          |         grp_neural_network_Pipeline_VITIS_LOOP_26_2_fu_270         |    3    |   4.83  |   190   |   399   |
|          |         grp_neural_network_Pipeline_VITIS_LOOP_32_3_fu_291         |    0    |   8.05  |   1581  |   1250  |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|    add   |                           add_ln60_fu_334                          |    0    |    0    |    0    |    13   |
|          |                           add_ln82_fu_372                          |    0    |    0    |    0    |    13   |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|   icmp   |                            cmp131_fu_366                           |    0    |    0    |    0    |    13   |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|          |                      input_0_read_read_fu_178                      |    0    |    0    |    0    |    0    |
|   read   |                      input_1_read_read_fu_184                      |    0    |    0    |    0    |    0    |
|          |                      input_2_read_read_fu_190                      |    0    |    0    |    0    |    0    |
|          |                      input_3_read_read_fu_196                      |    0    |    0    |    0    |    0    |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
| bitselect|                             tmp_fu_321                             |    0    |    0    |    0    |    0    |
|          |                            tmp_10_fu_358                           |    0    |    0    |    0    |    0    |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|   trunc  |                          trunc_ln60_fu_329                         |    0    |    0    |    0    |    0    |
|          |                          trunc_ln82_fu_353                         |    0    |    0    |    0    |    0    |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|
|   Total  |                                                                    |    11   |  54.967 |   2922  |   2748  |
|----------|--------------------------------------------------------------------|---------|---------|---------|---------|

Memories:
+---------------------+--------+--------+--------+--------+
|                     |  BRAM  |   FF   |   LUT  |  URAM  |
+---------------------+--------+--------+--------+--------+
|  exp_x_msb_1_table  |    0   |   25   |   13   |    -   |
|exp_x_msb_2_m_1_table|    0   |   25   |   13   |    -   |
|    f_x_lsb_table    |    0   |   11   |    6   |    -   |
|     layer1_bias     |    0   |    7   |    1   |    -   |
|    layer1_output    |    0   |   15   |    1   |    0   |
|   layer1_output_1   |    0   |   15   |    1   |    0   |
|   layer1_output_2   |    0   |   15   |    1   |    0   |
|   layer1_output_3   |    0   |   15   |    1   |    0   |
|  layer1_weight_tile |    0   |    9   |    1   |    0   |
| layer1_weight_tile_1|    0   |    9   |    1   |    0   |
| layer1_weight_tile_2|    0   |    9   |    1   |    0   |
| layer1_weight_tile_3|    0   |    9   |    1   |    0   |
|    layer1_weights   |    0   |    9   |    5   |    -   |
|  layer2_weight_tile |    0   |   10   |    1   |    0   |
| layer2_weight_tile_1|    0   |   10   |    1   |    0   |
| layer2_weight_tile_2|    0   |   10   |    1   |    0   |
| layer2_weight_tile_3|    0   |   10   |    1   |    0   |
|    layer2_weights   |    0   |   10   |    4   |    -   |
+---------------------+--------+--------+--------+--------+
|        Total        |    0   |   223  |   54   |    0   |
+---------------------+--------+--------+--------+--------+

* Register list:
+----------------------------------+--------+
|                                  |   FF   |
+----------------------------------+--------+
|          cmp131_reg_491          |    1   |
|conv_i_i_le10_lcssa17_load_reg_501|   16   |
|   conv_i_i_le10_lcssa17_reg_470  |   16   |
|conv_i_i_le12_lcssa19_load_reg_507|   16   |
|   conv_i_i_le12_lcssa19_reg_476  |   16   |
|   conv_i_i_le8_lcssa15_reg_464   |   16   |
|       input_0_read_reg_422       |   16   |
|       input_1_read_reg_427       |   16   |
|       input_2_read_reg_432       |   16   |
|       input_3_read_reg_437       |   16   |
|        max_val_loc_reg_416       |   16   |
|    p_0_0_0114_i1_load_reg_496    |   16   |
|       p_0_0_0114_i1_reg_458      |   16   |
|              reg_307             |   16   |
|         sum_2_loc_reg_410        |   16   |
|          tile_1_reg_451          |    4   |
|           tile_reg_403           |    4   |
|        trunc_ln60_reg_445        |    3   |
|        trunc_ln82_reg_482        |    3   |
+----------------------------------+--------+
|               Total              |   239  |
+----------------------------------+--------+

* Multiplexer (MUX) list: 
|--------------------------------------------------------------------|------|------|------|--------||---------||---------|
|                                Comp                                |  Pin | Size |  BW  | S x BW ||  Delay  ||   LUT   |
|--------------------------------------------------------------------|------|------|------|--------||---------||---------|
| grp_neural_network_Pipeline_VITIS_LOOP_62_2_VITIS_LOOP_63_3_fu_202 |  p2  |   2  |   3  |    6   ||    9    |
| grp_neural_network_Pipeline_VITIS_LOOP_84_7_VITIS_LOOP_85_8_fu_232 |  p2  |   2  |   3  |    6   ||    9    |
|         grp_neural_network_Pipeline_VITIS_LOOP_21_1_fu_243         |  p1  |   2  |  16  |   32   ||    9    |
|         grp_neural_network_Pipeline_VITIS_LOOP_21_1_fu_243         |  p2  |   2  |  16  |   32   ||    9    |
|         grp_neural_network_Pipeline_VITIS_LOOP_21_1_fu_243         |  p3  |   2  |  16  |   32   ||    9    |
|         grp_neural_network_Pipeline_VITIS_LOOP_92_9_fu_251         |  p1  |   2  |  16  |   32   ||    9    |
|         grp_neural_network_Pipeline_VITIS_LOOP_26_2_fu_270         |  p4  |   2  |  16  |   32   ||    9    |
|--------------------------------------------------------------------|------|------|------|--------||---------||---------|
|                                Total                               |      |      |      |   172  ||  11.27  ||    63   |
|--------------------------------------------------------------------|------|------|------|--------||---------||---------|



* Summary:
+-----------+--------+--------+--------+--------+--------+--------+
|           |  BRAM  |   DSP  |  Delay |   FF   |   LUT  |  URAM  |
+-----------+--------+--------+--------+--------+--------+--------+
|  Function |    -   |   11   |   54   |  2922  |  2748  |    -   |
|   Memory  |    0   |    -   |    -   |   223  |   54   |    0   |
|Multiplexer|    -   |    -   |   11   |    -   |   63   |    -   |
|  Register |    -   |    -   |    -   |   239  |    -   |    -   |
+-----------+--------+--------+--------+--------+--------+--------+
|   Total   |    0   |   11   |   66   |  3384  |  2865  |    0   |
+-----------+--------+--------+--------+--------+--------+--------+
