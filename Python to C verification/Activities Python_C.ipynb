{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83d72e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 16:08:22.951768: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 16:08:22.992778: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 16:08:22.993427: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 16:08:23.798581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "\n",
    "#os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69961520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b721174d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115943, 18) (49690, 18) (115943, 5) (49690, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('activities_preprocessed_approx.csv')\n",
    "X = df.values[:,:-1]\n",
    "Y = df.values[:,-1]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "Y = enc.fit_transform(Y[:, np.newaxis]).toarray()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe16683f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23189/23189 [==============================] - 24s 1ms/step - loss: 0.2240 - accuracy: 0.9325\n",
      "Epoch 2/10\n",
      "23189/23189 [==============================] - 23s 981us/step - loss: 0.1105 - accuracy: 0.9705\n",
      "Epoch 3/10\n",
      "23189/23189 [==============================] - 22s 969us/step - loss: 0.0946 - accuracy: 0.9751\n",
      "Epoch 4/10\n",
      "23189/23189 [==============================] - 23s 971us/step - loss: 0.0875 - accuracy: 0.9775\n",
      "Epoch 5/10\n",
      "23189/23189 [==============================] - 23s 973us/step - loss: 0.0814 - accuracy: 0.9787\n",
      "Epoch 6/10\n",
      "23189/23189 [==============================] - 23s 970us/step - loss: 0.0782 - accuracy: 0.9796\n",
      "Epoch 7/10\n",
      "23189/23189 [==============================] - 22s 970us/step - loss: 0.0748 - accuracy: 0.9805\n",
      "Epoch 8/10\n",
      "23189/23189 [==============================] - 22s 968us/step - loss: 0.0728 - accuracy: 0.9813\n",
      "Epoch 9/10\n",
      "23189/23189 [==============================] - 23s 970us/step - loss: 0.0705 - accuracy: 0.9816\n",
      "Epoch 10/10\n",
      "23189/23189 [==============================] - 23s 972us/step - loss: 0.0681 - accuracy: 0.9822\n",
      "1553/1553 [==============================] - 2s 928us/step - loss: 0.0869 - accuracy: 0.9811\n",
      "Loss: 0.08688576519489288, Accuracy: 0.9811229705810547\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=18, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=5, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "385360e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553/1553 [==============================] - 1s 800us/step\n",
      "Accuracy: 0.9811229623666734\n"
     ]
    }
   ],
   "source": [
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_keras = model.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(Y_test, axis=1), np.argmax(y_keras, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fea110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = enc.inverse_transform(Y_test)\n",
    "y_test = [i[0] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66b0995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset has been saved to 'test_dataset.c'\n"
     ]
    }
   ],
   "source": [
    "# Create the C file\n",
    "with open('Activities_testdata/test_dataset.c', 'w') as f:\n",
    "    # Write the data samples array\n",
    "    f.write(\"float test_data[%d][%d] = {\\n\" % (X_test.shape[0], X_test.shape[1]))\n",
    "    for row in X_test:\n",
    "        f.write(\"    {%s},\\n\" % \", \".join(f\"{x:.6f}f\" for x in row))\n",
    "    f.write(\"};\\n\\n\")\n",
    "\n",
    "    # Write the labels array\n",
    "    f.write(\"int test_labels[%d] = {\\n\" % len(y_test))\n",
    "    f.write(\"    %s\\n\" % \", \".join(map(str, y_test)))\n",
    "    f.write(\"};\\n\")\n",
    "\n",
    "print(\"Test dataset has been saved to 'test_dataset.c'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174b60c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and biases have been saved to 'weights.cpp'\n"
     ]
    }
   ],
   "source": [
    "# Get the weights and biases\n",
    "layer1_weights = model.layers[0].get_weights()[0].T\n",
    "layer1_bias = model.layers[0].get_weights()[1]\n",
    "layer2_weights = model.layers[1].get_weights()[0].T\n",
    "layer2_bias = model.layers[1].get_weights()[1]\n",
    "\n",
    "# Write weights and biases to weights.cpp\n",
    "with open('Activities_testdata/weights.cpp', 'w') as f:\n",
    "    f.write('#include <vector>\\n\\n')\n",
    "    \n",
    "    f.write('std::vector<std::vector<float>> layer1_weights = {\\n')\n",
    "    for row in layer1_weights:\n",
    "        f.write('    {' + ', '.join(f'{x:.6f}f' for x in row) + '},\\n')\n",
    "    f.write('};\\n\\n')\n",
    "\n",
    "    f.write('std::vector<float> layer1_bias = {')\n",
    "    f.write(', '.join(f'{x:.6f}f' for x in layer1_bias))\n",
    "    f.write('};\\n\\n')\n",
    "\n",
    "    f.write('std::vector<std::vector<float>> layer2_weights = {\\n')\n",
    "    for row in layer2_weights:\n",
    "        f.write('    {' + ', '.join(f'{x:.6f}f' for x in row) + '},\\n')\n",
    "    f.write('};\\n\\n')\n",
    "\n",
    "    f.write('std::vector<float> layer2_bias = {')\n",
    "    f.write(', '.join(f'{x:.6f}f' for x in layer2_bias))\n",
    "    f.write('};\\n')\n",
    "\n",
    "print(\"Weights and biases have been saved to 'weights.cpp'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6094a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!g++ -std=c++11 Activities_testdata/test.cpp -o Activities_testdata/test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5538c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.8201%\r\n"
     ]
    }
   ],
   "source": [
    "!./Activities_testdata/test_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0d77b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
