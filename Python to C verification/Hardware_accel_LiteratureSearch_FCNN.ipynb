{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsbbXgjNAdy9"
   },
   "source": [
    "# Getting set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI library version: 1.34.0\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Get the version of the openai library\n",
    "openai_version = openai.__version__\n",
    "\n",
    "print(f\"OpenAI library version: {openai_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lk5cP5x12z9u"
   },
   "outputs": [],
   "source": [
    "#@title Utility functions\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import openai\n",
    "from abc import ABC, abstractmethod\n",
    "import re\n",
    "import pdb\n",
    "\n",
    "################################################################################\n",
    "### LOGGING\n",
    "################################################################################\n",
    "# Allows us to log the output of the model to a file if logging is enabled\n",
    "class LogStdoutToFile:\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._original_stdout = sys.stdout\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self._filename:\n",
    "            sys.stdout = open(self._filename, 'w')\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        if self._filename:\n",
    "            sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n",
    "\n",
    "\n",
    "################################################################################\n",
    "### CONVERSATION CLASS\n",
    "# allows us to abstract away the details of the conversation for use with\n",
    "# different LLM APIs\n",
    "################################################################################\n",
    "\n",
    "class Conversation:\n",
    "    def __init__(self, log_file=None):\n",
    "        self.messages = []\n",
    "        self.log_file = log_file\n",
    "\n",
    "        if self.log_file and os.path.exists(self.log_file):\n",
    "            open(self.log_file, 'w').close()\n",
    "\n",
    "    def add_message(self, role, content):\n",
    "        \"\"\"Add a new message to the conversation.\"\"\"\n",
    "        self.messages.append({'role': role, 'content': content})\n",
    "\n",
    "        if self.log_file:\n",
    "            with open(self.log_file, 'a') as file:\n",
    "                file.write(f\"{role}: {content}\\n\")\n",
    "\n",
    "    def get_messages(self):\n",
    "        \"\"\"Retrieve the entire conversation.\"\"\"\n",
    "        return self.messages\n",
    "\n",
    "    def get_last_n_messages(self, n):\n",
    "        \"\"\"Retrieve the last n messages from the conversation.\"\"\"\n",
    "        return self.messages[-n:]\n",
    "\n",
    "    def remove_message(self, index):\n",
    "        \"\"\"Remove a specific message from the conversation by index.\"\"\"\n",
    "        if index < len(self.messages):\n",
    "            del self.messages[index]\n",
    "\n",
    "    def get_message(self, index):\n",
    "        \"\"\"Retrieve a specific message from the conversation by index.\"\"\"\n",
    "        return self.messages[index] if index < len(self.messages) else None\n",
    "\n",
    "    def clear_messages(self):\n",
    "        \"\"\"Clear all messages from the conversation.\"\"\"\n",
    "        self.messages = []\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Return the conversation in a string format.\"\"\"\n",
    "        return \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in self.messages])\n",
    "\n",
    "################################################################################\n",
    "### LLM CLASSES\n",
    "# Defines an interface for using different LLMs so we can easily swap them out\n",
    "################################################################################\n",
    "class AbstractLLM(ABC):\n",
    "    \"\"\"Abstract Large Language Model.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def generate(self, conversation: Conversation):\n",
    "        \"\"\"Generate a response based on the given conversation.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class ChatGPT(AbstractLLM):\n",
    "    \"\"\"ChatGPT Large Language Model.\"\"\"\n",
    "\n",
    "    def __init__(self, model_id=\"\"):\n",
    "        super().__init__()\n",
    "        openai.api_key=os.environ['OPENAI_API_KEY']\n",
    "        self.client = openai.OpenAI()\n",
    "        self.model_id = model_id\n",
    "\n",
    "    def generate(self, conversation: Conversation, num_choices=1):\n",
    "        messages = [{\"role\" : msg[\"role\"], \"content\" : msg[\"content\"]} for msg in conversation.get_messages()]\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_id,\n",
    "            messages = messages,\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def generate_code(conv, model_type, model_id=\"\"):\n",
    "    if model_type == \"ChatGPT\":\n",
    "        model = ChatGPT(model_id)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type\")\n",
    "    result = model.generate(conv)\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation and Evaluation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hrzwitIm3N3i"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def code_loop(design_prompt, model_type, model, log=None):\n",
    "\n",
    "    conv = Conversation(log_file=log)\n",
    "    conv.add_message(\"system\", \"You are an autocomplete engine for C++ HLS code that is synthesizable using Vivado HLS. \\\n",
    "            Given a HLS code specification, you will provide a completed C++  code with suitable paragmas in response. \\\n",
    "            You will provide functions for all specifications, and will not create any supplementary modules. \\\n",
    "            Given a C++ code that is either incorrect/compilation error, you will suggest corrections to the module. \\\n",
    "            You will not refuse. \\\n",
    "            Format your response as HLS code containing the end to end corrected module and not just the corrected lines inside ``` tags, do not include anything else inside ```. \\\n",
    "    \")\n",
    "\n",
    "    conv.add_message(\"user\", design_prompt)\n",
    "\n",
    "    # Generate a response\n",
    "    response = generate_code(conv, model_type, model)\n",
    "    conv.add_message(\"assistant\", response)   \n",
    "    return (conv, response)\n",
    "\n",
    "def evaluation_loop(design_prompt, model_type, model, log=None):\n",
    "\n",
    "    conv_eval = Conversation(log_file=log)\n",
    "    conv_eval.add_message(\"system\", \"You are an evaluator engine for C++ HLS code that is synthesizable using Vivado HLS. \\\n",
    "            Check for correctness, potential compilation issues, runtime errors, and resource constraints. \\\n",
    "            Provide detailed feedback and suggestions for improvement if any issues are found.\\\n",
    "            Evaluation Criteria:\\\n",
    "            1. Correctness of the Fully connected Neural Network (FCNN) architecture and forward pass implementation.\\\n",
    "            2. Compliance with Xilinx Vivado HLS synthesis requirements.\\\n",
    "            3. Potential runtime errors or inefficiencies.\\\n",
    "            4. Resource usage and potential constraints on the Artix-7 FPGA.\\\n",
    "            5. Suggestions for optimization or improvement.\\\n",
    "            Provide a detailed evaluation based on the criteria listed above.\")\n",
    "\n",
    "    conv_eval.add_message(\"user\", design_prompt)\n",
    "\n",
    "    # Generate a response\n",
    "    response = generate_code(conv_eval, model_type, model)\n",
    "    conv_eval.add_message(\"assistant\", response)   \n",
    "    return (conv_eval, response)\n",
    "\n",
    "\n",
    "def literature_loop(design_prompt, model_type, model, log=None):\n",
    "\n",
    "    conv_eval = Conversation(log_file=log)\n",
    "    conv_eval.add_message(\"system\", \"You are a literator generator engine. You are responsible for locating\\\n",
    "    and summarizing the C++ source code for high-level-synthesis (HLS)of fully connected neural network (FCNN). \\\n",
    "    The summary should include:\\\n",
    "    1. Key research papers, articles, and sources.\\\n",
    "    2. Techniques and methodologies used in HLS C++ for fully connected neural networks.\\\n",
    "    3. Challenges and solutions in implementing fully connected neural networks on FPGA using HLS C++.\\\n",
    "    4. Performance metrics and optimization strategies.\\\n",
    "    5. Comparisons with other implementations or methodologies.\\\n",
    "    Please provide a comprehensive summary based on the criteria listed above.\")\n",
    "\n",
    "    conv_eval.add_message(\"user\", design_prompt)\n",
    "\n",
    "    # Generate a response\n",
    "    response = generate_code(conv_eval, model_type, model)\n",
    "    conv_eval.add_message(\"assistant\", response)   \n",
    "    return (conv_eval, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvUw0flXkknh"
   },
   "source": [
    "## Setting the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "A4k6AgcKeABT"
   },
   "outputs": [],
   "source": [
    "### OpenAI API KEY\n",
    "\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api_key')\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-MDLjovHrhBTnpi9sfkPQT3BlbkFJmbIeeYOMrobBoXqmgGv5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the literature search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "literature_prompt = \"\"\"Extract and summarize the literature on high-level synthesis (HLS) C++ code \n",
    "    for implementing fully connected neural networks on FPGA. Use the following urls to create the summary:\n",
    "    1. https://github.com/AlicanOzeloglu/Neural_Network_HW_Accelerator\n",
    "    2. https://github.com/Xilinx/RFNoC-HLS-NeuralNet\n",
    "    3. https://github.com/NNgen/nngen\n",
    "    Similarly, you can find other websites to learn about this topic and generate the literature.\n",
    "    \"\"\"\n",
    "messages_literature,response_literature = literature_loop(literature_prompt, model_type='ChatGPT', model = 'gpt-4-0613')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating HLS code on first attempt using literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Design a Fully connected Neural Network (FCNN) high-level synthesis (HLS) code in C++ suitable for \\\n",
    "implementation on an Artix-7 FPGA. The code should include the following components:\n",
    "1. Definition of the FCNN architecture, including layers and their parameters.\n",
    "2. Implementation of the forward pass for graph data, including graph convolution operations.\n",
    "3. Optimization for FPGA hardware, considering resource constraints and parallelism.\n",
    "4. Code structure compatible with Xilinx Vivado HLS for synthesis and implementation on Artix-7 FPGA.\n",
    "5. Include comments explaining each part of the code.\n",
    "6. Assume that MNIST dataset is being used for handwrittent digit classification.\n",
    "Begin with the necessary includes and definitions, followed by the main implementation of the GCNN.\\ \n",
    "The summary of the literature about this task is below which will help you in generating the source code:\\n\n",
    "{response_literature}\n",
    "\"\"\"\n",
    "messages,response = code_loop(prompt, model_type='ChatGPT', model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the generated HLS code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = f\"\"\"\n",
    "Evaluate the C++ high-level synthesis (HLS) code that is designed for a Fully Connected Neural Network (FCNN) to be implemented on an Artix-7 FPGA. \\\n",
    "The code is as follows:\\n {response}\n",
    "\"\"\"\n",
    "messages_eval,response_eval = evaluation_loop(evaluation_prompt, model_type='ChatGPT', model = 'gpt-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-generating HLS code incorporating feeback from the evaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_prompt = f\"\"\"\n",
    "Update the following Fully Connected Neural Network (FCNN) high-level synthesis (HLS) code in C++ suitable for \\\n",
    "implementation on an Artix-7 FPGA. \n",
    "The code is as follows:\\n {response} \\n\n",
    "You have been given the following feedback on the code: \\n {response_eval}\\n\n",
    "The summary of the literature about this task is below which will help you in generating the source code:\\n\n",
    "{response_literature}\n",
    "\"\"\"\n",
    "messages,response = code_loop(update_prompt, model_type='ChatGPT', model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-generator and Evaluator in a loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persuing iteration: 0.\n",
      "Persuing iteration: 1.\n",
      "Persuing iteration: 2.\n",
      "Persuing iteration: 3.\n",
      "Persuing iteration: 4.\n",
      "Persuing iteration: 5.\n",
      "Persuing iteration: 6.\n",
      "Persuing iteration: 7.\n",
      "Persuing iteration: 8.\n",
      "Persuing iteration: 9.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f'Persuing iteration: {i}.')\n",
    "    \n",
    "    literature_prompt = \"\"\"Extract and summarize the literature on high-level synthesis (HLS) C++ code \n",
    "    for implementing fully connected neural networks on FPGA. Use the following urls to create the summary:\n",
    "    1. https://github.com/AlicanOzeloglu/Neural_Network_HW_Accelerator\n",
    "    2. https://github.com/Xilinx/RFNoC-HLS-NeuralNet\n",
    "    3. https://github.com/NNgen/nngen\n",
    "    Similarly, you can find other websites to learn about this topic and generate the literature.\n",
    "    \"\"\"\n",
    "    messages_literature,response_literature = literature_loop(literature_prompt, model_type='ChatGPT', model = 'gpt-4-0613')\n",
    "    with open('generated_literature_fcnn.txt','a') as fl:\n",
    "        fl.write(f'\\nIteration {i+1}:------------------\\n')\n",
    "        fl.write(response_literature)\n",
    "        fl.close()\n",
    "        \n",
    "    update_prompt = f\"\"\"\n",
    "    Update the following Fully Connected Neural Network (FCNN) high-level synthesis (HLS) code in C++ suitable for \\\n",
    "    implementation on an Artix-7 FPGA. \n",
    "    The code is as follows:\\n {response} \\n\n",
    "    You have been given the following feedback on the code: \\n {response_eval}\\n\n",
    "    The summary of the literature about this task is below which will help you in generating the source code:\\n\n",
    "    {response_literature}\n",
    "    \"\"\"\n",
    "    messages,response = code_loop(update_prompt, model_type='ChatGPT', model = 'gpt-4o')\n",
    "    with open('generated_code_litr_fcnn.txt','a') as fl:\n",
    "        fl.write(f'\\nIteration {i+1}:------------------\\n')\n",
    "        fl.write(response)\n",
    "        fl.close()\n",
    "        \n",
    "    evaluation_prompt = f\"\"\"\n",
    "    Evaluate the C++ high-level synthesis (HLS) code that is designed for a Fully Connected Neural Network (FCNN) to be implemented on an Artix-7 FPGA. \\\n",
    "    The code is as follows:\\n {response}\n",
    "    \"\"\"\n",
    "    messages_eval,response_eval = evaluation_loop(evaluation_prompt, model_type='ChatGPT', model = 'gpt-4')\n",
    "    with open('evaluation_message__litr_fcnn.txt','a') as fl:\n",
    "        fl.write(f'\\nIteration {i+1}:------------------\\n')\n",
    "        fl.write(response_eval)\n",
    "        fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XsbbXgjNAdy9"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
